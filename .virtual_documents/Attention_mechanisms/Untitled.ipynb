


import torch





#Example. input sentence embedded into 3-dimensional vectors.
inputs = torch.tensor(
[[0.43, 0.15, 0.89], # Your (x^1)
[0.55, 0.87, 0.66], # journey (x^2)
[0.57, 0.85, 0.64], # starts (x^3)
[0.22, 0.58, 0.33], # with (x^4)
[0.77, 0.25, 0.10], # one (x^5)
[0.05, 0.80, 0.55]] # step (x^6)
)






query=inputs[1]
attn_scores_2=torch.empty(inputs.shape[0]) #to store attention scores for x2
for i,xi in enumerate(inputs):
    attn_scores_2[i]=torch.dot(xi,query)
print(attn_scores_2)





#Normalizing using softmax (better at handling extreme values and has more desirable gradient properties during training)
attn_weights_2= torch.softmax(attn_weights_2,dim=0)
print(attn_weights_2_norm)





query=inputs[1]
context_vec_2=torch.zeros(query.shape) #to store attention scores for x2
for i,xi in enumerate(inputs):
    context_vec_2+=attn_weights_2[i]*xi
print(context_vec_2)


#Computing for all input tokens
attn_scores=torch.empty(inputs.shape[0],inputs.shape[0])
for i, xi in enumerate(inputs):
    for j,xj in enumerate(inputs):
            attn_scores[i,j]=torch.dot(xi,xj)
print(attn_scores)


#Faster way 
attn_scores=inputs@inputs.T
print(attn_scores)


#Normalizing
attn_weights=torch.softmax(attn_scores,dim=1)
print(attn_weights)


#Context vector
all_context_vecs=attn_weights@inputs
print(all_context_vecs)

























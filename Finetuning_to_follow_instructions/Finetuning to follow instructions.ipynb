{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df875bc5-bd03-4269-b0c3-6ae8fa20b60c",
   "metadata": {},
   "source": [
    "The objective is to finetune an LLM to follow instructions, using an instruction dataset consisting in input-output pairs.\n",
    "Examples:\n",
    "- Instruction: Convert 45 kilometers to meters -> Response: 45 kilometers is 45000 meters\n",
    "- Provide a synonym for bright -> A synonym for \"bright\" is \"radiant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bce62b-a83c-42a4-919b-95fa2cb6a00c",
   "metadata": {},
   "source": [
    "***1) Loading the dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eebcddb-4393-4805-a820-29aa1130f97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "#Loading the dataset\n",
    "#Dataset consists of 1100 instruction-response pairs\n",
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import numpy as np\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://github.com/luiscstr/LLMs/blob/main/Finetuning_to_follow_instructions/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9330aa81-e95c-4bef-82a9-b21f0e742387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "326fe309-87a3-4399-8d96-d4946d6e6159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c98d968-f845-4eef-bb72-a21b1ef53d4d",
   "metadata": {},
   "source": [
    "There are various prompt styles. We will use Alpaca style, which consist in a structure with defined sections for instruction, input, an response. Other example of format is Phi-3 which employes a <user> and <assistant> format\n",
    "\n",
    "Example of Alpaca Style:\n",
    "\n",
    "***Below is an instruction that describes a task. Write a response that appropiately completes the request***\n",
    "\n",
    "***###Instruction:***\n",
    "<br> \n",
    "Identify the correct spelling of the following word\n",
    "\n",
    "***###Input:***\n",
    "<br> \n",
    "Ocassion\n",
    "\n",
    "\n",
    "***###Response:***\n",
    "<br> \n",
    "The correct spelling is 'Occasion.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f8ae8d-c9db-4a4a-b286-32f6921c966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a format function to format the instructions with Alpaca Style\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5304be38-0dc1-42d2-a4f8-fc373d999fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ec15e31-7379-4051-84d8-25fe6d2e9513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "#If there is no input the input sections is skipped\n",
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "232b1b19-3d2d-49c9-809f-810da4754825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "#Splitting in train, test, validation\n",
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)   # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # 5% for validation\n",
    " \n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    " \n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4c185c-b785-44aa-9e2b-0ce68083fd06",
   "metadata": {},
   "source": [
    "***2. Batching the dataset***\n",
    "\n",
    "Need to create a custom collate function to handle the requirements and formatting of the instructions dataset. \n",
    "Steps:\n",
    "- Format data using prompt template\n",
    "- Tokenize formated data\n",
    "- Adjust length with padding tokens\n",
    "- Create target token IDs\n",
    "- Replace padding tokens with placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e031637d-d4b2-4968-82e9-caa3b31f4248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class to format the data\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    " \n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data: \n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de752aa2-5dbc-41cd-9a2d-48f9bc6d0b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "#Tokenizer\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a87993bc-ded1-4aa9-ac43-cf2688330034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjusting length with padding tokens\n",
    "#Defining a custom collate function that pads the training data in each batch to have the same length (length of the longest\n",
    "#text in the batch) The function allow different batchs to have different lengths.\n",
    "def custom_collate_draft(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch) #Find the longest sequence in the batch\n",
    "    inputs_lst, targets_lst = [], []\n",
    " \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    " \n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "    \n",
    "        inputs = torch.tensor(padded[:-1]) #Remove extra padded token added earlier\n",
    "        targets = torch.tensor(padded[1:]) #Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "        \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor,targets_tensor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45eece41-b7f0-4757-acb6-1f12a778cf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "inputs, targets = custom_collate_draft(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "474372ce-d90f-4ddc-bb22-4c09f692f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify our custom collate function to replace tokens with ID 50256 with -100 in the target lists. This is\n",
    "#to ignore the end-of-text tokens added as a padding when calculating the cross entropy loss function\n",
    "#Also introduces an allowed_max_length parameter to optionally limit the length of the samples. \n",
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    " \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    " \n",
    "        mask = targets == pad_token_id   #Replace all but the first padding tokens in targets by ignore_index\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    " \n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    " \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    " \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc490c95-f8e2-4d0e-a2a2-7003941f8450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1044fd6c-f39f-4f70-a061-b7de1a5a5792",
   "metadata": {},
   "source": [
    "There are two approaches with the target text:\n",
    "- Masking the instruction tokens (instruction + input) and keep only the response. The idea is to train the model to focus on generating responses rather than memorizing instructions.\n",
    "- Don't mask the instructions.\n",
    "\n",
    "Researchers are divided bon whether masking the instructions is universally benficial. We will try and compare both approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec30ee9a-6cac-41f5-9e0f-b4f8c0d9f00e",
   "metadata": {},
   "source": [
    "***3. Creating the data loaders***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d27d038c-896b-443b-8475-899c474f5f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\"\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f25fe61-6925-4a9d-9708-e818c1b38373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15e65939-7637-4755-9200-99ceae676aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab30a301-16f4-49d9-a0ec-f409d91d410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3352b59d-04d7-48ca-8ec7-8561d16e93b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "848a76a0-a374-481e-b8c6-1c5994ee375f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63c7add4-cb87-427a-ab57-a872ec44a8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e61b2d8-4e09-420c-b327-6964a97bb292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf02e73-df61-4210-a809-c281d91e6eba",
   "metadata": {},
   "source": [
    "***4) Loading pretrained LLM***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6451bf4c-baed-4a83-84f9-6632c66acd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Classes import GPTModel,load_weights_into_gpt,generate,text_to_token_ids,token_ids_to_text, calc_loss_loader, train_model_simple, plot_losses\n",
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ae31593-04fc-4d15-8c7f-e6114ddd3b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\355M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\355M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    " \n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    " \n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    " \n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    " \n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42381b2-b457-4836-b71f-466f4257d8d8",
   "metadata": {},
   "source": [
    "First, we will assess the pretrained LLM without finetunning to obtain a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc29cdb0-bd38-4c5c-8d30-5a90c5f8bde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68a58bf0-f388-4dc8-9a7c-ab75012e7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4553ba8d-add4-40e2-bc55-0c67ac3487dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()#remocing the input text\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b945066-1c69-41b2-a72c-705f405b98c8",
   "metadata": {},
   "source": [
    "The model is not able to follow the instruction. It seems is just copying the instruction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6e615-a4cb-40f9-b766-a4d1f2ff12d7",
   "metadata": {},
   "source": [
    "***5) Finetunning the LLM on instruction data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e22fe82e-8994-4f12-8f6b-7ba7ff95db5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.825910139083862\n",
      "Validation loss: 3.761934280395508\n"
     ]
    }
   ],
   "source": [
    "#Calculating the initial loss for the training and validation sets\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    " \n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    " \n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4125b15-8deb-46a0-b70c-5ccc18a6684e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.102\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
      "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
      "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.532, Val loss 0.729\n",
      "Ep 1 (Step 000075): Train loss 0.569, Val loss 0.728\n",
      "Ep 1 (Step 000080): Train loss 0.605, Val loss 0.725\n",
      "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.709\n",
      "Ep 1 (Step 000090): Train loss 0.562, Val loss 0.691\n",
      "Ep 1 (Step 000095): Train loss 0.501, Val loss 0.682\n",
      "Ep 1 (Step 000100): Train loss 0.503, Val loss 0.677\n",
      "Ep 1 (Step 000105): Train loss 0.564, Val loss 0.670\n",
      "Ep 1 (Step 000110): Train loss 0.555, Val loss 0.666\n",
      "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.664\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.672\n",
      "Ep 2 (Step 000125): Train loss 0.451, Val loss 0.686\n",
      "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
      "Ep 2 (Step 000135): Train loss 0.405, Val loss 0.681\n",
      "Ep 2 (Step 000140): Train loss 0.409, Val loss 0.681\n",
      "Ep 2 (Step 000145): Train loss 0.368, Val loss 0.681\n",
      "Ep 2 (Step 000150): Train loss 0.382, Val loss 0.675\n",
      "Ep 2 (Step 000155): Train loss 0.413, Val loss 0.675\n",
      "Ep 2 (Step 000160): Train loss 0.415, Val loss 0.683\n",
      "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.685\n",
      "Ep 2 (Step 000170): Train loss 0.323, Val loss 0.681\n",
      "Ep 2 (Step 000175): Train loss 0.337, Val loss 0.669\n",
      "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.656\n",
      "Ep 2 (Step 000185): Train loss 0.415, Val loss 0.657\n",
      "Ep 2 (Step 000190): Train loss 0.341, Val loss 0.648\n",
      "Ep 2 (Step 000195): Train loss 0.329, Val loss 0.635\n",
      "Ep 2 (Step 000200): Train loss 0.310, Val loss 0.635\n",
      "Ep 2 (Step 000205): Train loss 0.352, Val loss 0.631\n",
      "Ep 2 (Step 000210): Train loss 0.367, Val loss 0.630\n",
      "Ep 2 (Step 000215): Train loss 0.395, Val loss 0.634\n",
      "Ep 2 (Step 000220): Train loss 0.302, Val loss 0.648\n",
      "Ep 2 (Step 000225): Train loss 0.348, Val loss 0.661\n",
      "Ep 2 (Step 000230): Train loss 0.295, Val loss 0.656\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 12.83 minutes.\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "import time\n",
    " \n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    " \n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    " \n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09d4150d-6220-42b2-94ab-4402a9f55df7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MaxNLocator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, num_epochs, \u001b[38;5;28mlen\u001b[39m(train_losses))\n\u001b[1;32m----> 2\u001b[0m plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
      "File \u001b[1;32m~\\LLMs\\LLMs\\Finetuning_to_follow_instructions\\Classes.py:432\u001b[0m, in \u001b[0;36mplot_losses\u001b[1;34m(epochs_seen, tokens_seen, train_losses, val_losses)\u001b[0m\n\u001b[0;32m    430\u001b[0m ax1\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    431\u001b[0m ax1\u001b[38;5;241m.\u001b[39mlegend(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper right\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 432\u001b[0m ax1\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mset_major_locator(MaxNLocator(integer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))  \u001b[38;5;66;03m# only show integer labels on x-axis\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# Create a second x-axis for tokens seen\u001b[39;00m\n\u001b[0;32m    435\u001b[0m ax2 \u001b[38;5;241m=\u001b[39m ax1\u001b[38;5;241m.\u001b[39mtwiny()  \u001b[38;5;66;03m# Create a second x-axis that shares the same y-axis\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MaxNLocator' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810c8563-e326-4da7-8e5b-7f3f5723a4f0",
   "metadata": {},
   "source": [
    "The generated responses are correct. The loss curves also indicate that the model's performance on both training and validation sets improve over the training, specially during the initial pahse of training, \n",
    "However, the most crucial aspect is the response quality and correctness, which need to be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139259fa-2a2f-4ba9-95e9-14f27d06a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further work\n",
    "#Using other kind of prompting\n",
    "#Use alpaca dataset his dataset contains 52,002 entries, which is approximately 50 times more than those we used in this chapter, and most entries are longer as well. Thus, it's highly recommended to conduct the training using a GPU to accelerate the finetuning process. If you encounter out-of-memory errors, consider reducing the batch_size from 8 to 4, 2, or even 1. Additionally, lowering the allowed_max_length from 1024 to 512 or 256 can further help manage memory issues.\n",
    "#Evaluate model using Open AI rather than Llama 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb61353-b90f-4713-9bd4-537db68a4797",
   "metadata": {},
   "source": [
    "***6) Evaluating the LLM***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78fc8ef8-4f37-4adf-831c-9a502d8abf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Gnerating responses for the three first instructions and comparing agains the true responses\n",
    "torch.manual_seed(123)\n",
    " \n",
    "for entry in test_data[:3]: \n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate( \n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    " \n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e857cec7-1906-4164-ba24-1e02f7a3a06e",
   "metadata": {},
   "source": [
    "The models seems to perform relatively we. The first and third are correct. The second one is partially correct because answers cumulus cloud vs cumulomimbus, which is not exactly the same.\n",
    "\n",
    "Inspect all instructions this way would be too time consuming. We will use an approach inspired vy AlpacaEval (https://tatsu-lab.github.io/alpaca_eval/) to leverage another LLM to evaluate our model's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf648d7c-613c-4531-b511-87aba82c082d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [01:44<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "#Generating the responses of the test set and add them to the test_set file\n",
    "from tqdm import tqdm\n",
    " \n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    " \n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    " \n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35d5614e-435d-4c4b-9d2b-2a530a130abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a cheetah.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2df88115-d68b-46f8-bf3b-4a9fab4f1f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "#Saving model\n",
    "import re\n",
    " \n",
    "# Remove white spaces and parentheses from file name\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n",
    "#The saved model can then be loaded via model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0af95ae-215a-4df6-b13c-01a9d35550ab",
   "metadata": {},
   "source": [
    "We will use LLama 3 8B via Ollama to evaluate our LLM (ollama run llama3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99e43d36-1f95-4088-b37f-476b6812677d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "#After initiating Ollama3 we verify that is running\n",
    "import psutil\n",
    " \n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    " \n",
    "ollama_running = check_if_running(\"ollama\")\n",
    " \n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbd29dbf-47a8-48e8-aead-2de9c5d3764a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo load the model\\nimport json\\nfrom tqdm import tqdm\\n \\nfile_path = \"instruction-data-with-response.json\"\\nwith open(file_path, \"r\") as file:\\n    test_data = json.load(file)\\n \\ndef format_input(entry):\\n    instruction_text = (\\n        f\"Below is an instruction that describes a task. \"\\n        f\"Write a response that appropriately completes the request.\"\\n        f\"\\n\\n### Instruction:\\n{entry[\\'instruction\\']}\"\\n    )\\n \\n    input_text = f\"\\n\\n### Input:\\n{entry[\\'input\\']}\" if entry[\"input\"] else \"\"\\n       return instruction_text + input_text\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "To load the model\n",
    "'''\n",
    "import json\n",
    "from tqdm import tqdm\n",
    " \n",
    "file_path = \"instruction-data-with-response.json\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    test_data = json.load(file)\n",
    " \n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    " \n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "       return instruction_text + input_text\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "466c8d97-a5c4-4b44-a18c-d00eefe1e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative way to inrecat with Ollama via REST API\n",
    "'''\n",
    "import urllib.request\n",
    " \n",
    "def query_model(prompt, model=\"llama3\", url=\"http://localhost:11434/api/chat\"):\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"seed\": 123,        # for deterministic responses\n",
    "        \"temperature\": 0,   # for deterministic responses\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    " \n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "    request = urllib.request.Request(url, data=payload, method=\"POST\")\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    " \n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    " \n",
    "    return response_data\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e89e21-14dc-469b-937b-e6d1ddfb4009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

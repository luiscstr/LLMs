{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df875bc5-bd03-4269-b0c3-6ae8fa20b60c",
   "metadata": {},
   "source": [
    "The objective is to finetune an LLM to follow instructions, using an instruction dataset consisting in input-output pairs.\n",
    "Examples:\n",
    "- Instruction: Convert 45 kilometers to meters -> Response: 45 kilometers is 45000 meters\n",
    "- Provide a synonym for bright -> A synonym for \"bright\" is \"radiant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bce62b-a83c-42a4-919b-95fa2cb6a00c",
   "metadata": {},
   "source": [
    "***1) Loading the dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9eebcddb-4393-4805-a820-29aa1130f97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "#Loading the dataset\n",
    "#Dataset consists of 1100 instruction-response pairs\n",
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import numpy as np\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://github.com/luiscstr/LLMs/blob/main/Finetuning_to_follow_instructions/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9330aa81-e95c-4bef-82a9-b21f0e742387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "326fe309-87a3-4399-8d96-d4946d6e6159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c98d968-f845-4eef-bb72-a21b1ef53d4d",
   "metadata": {},
   "source": [
    "There are various prompt styles. We will use Alpaca style, which consist in a structure with defined sections for instruction, input, an response. Other example of format is Phi-3 which employes a <user> and <assistant> format\n",
    "\n",
    "Example of Alpaca Style:\n",
    "\n",
    "***Below is an instruction that describes a task. Write a response that appropiately completes the request***\n",
    "\n",
    "***###Instruction:***\n",
    "<br> \n",
    "Identify the correct spelling of the following word\n",
    "\n",
    "***###Input:***\n",
    "<br> \n",
    "Ocassion\n",
    "\n",
    "\n",
    "***###Response:***\n",
    "<br> \n",
    "The correct spelling is 'Occasion.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f8ae8d-c9db-4a4a-b286-32f6921c966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a format function to format the instructions with Alpaca Style\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5304be38-0dc1-42d2-a4f8-fc373d999fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec15e31-7379-4051-84d8-25fe6d2e9513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "#If there is no input the input sections is skipped\n",
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "232b1b19-3d2d-49c9-809f-810da4754825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "#Splitting in train, test, validation\n",
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)   # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # 5% for validation\n",
    " \n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    " \n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4c185c-b785-44aa-9e2b-0ce68083fd06",
   "metadata": {},
   "source": [
    "***2. Batching the dataset***\n",
    "\n",
    "Need to create a custom collate function to handle the requirements and formatting of the instructions dataset. \n",
    "Steps:\n",
    "- Format data using prompt template\n",
    "- Tokenize formated data\n",
    "- Adjust length with padding tokens\n",
    "- Create target token IDs\n",
    "- Replace padding tokens with placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e031637d-d4b2-4968-82e9-caa3b31f4248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class to format the data\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    " \n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data: \n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de752aa2-5dbc-41cd-9a2d-48f9bc6d0b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "#Tokenizer\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a87993bc-ded1-4aa9-ac43-cf2688330034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjusting length with padding tokens\n",
    "#Defining a custom collate function that pads the training data in each batch to have the same length (length of the longest\n",
    "#text in the batch) The function allow different batchs to have different lengths.\n",
    "def custom_collate_draft(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch) #Find the longest sequence in the batch\n",
    "    inputs_lst, targets_lst = [], []\n",
    " \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    " \n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "    \n",
    "        inputs = torch.tensor(padded[:-1]) #Remove extra padded token added earlier\n",
    "        targets = torch.tensor(padded[1:]) #Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "        \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor,targets_tensor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45eece41-b7f0-4757-acb6-1f12a778cf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "inputs, targets = custom_collate_draft(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "474372ce-d90f-4ddc-bb22-4c09f692f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify our custom collate function to replace tokens with ID 50256 with -100 in the target lists. This is\n",
    "#to ignore the end-of-text tokens added as a padding when calculating the cross entropy loss function\n",
    "#Also introduces an allowed_max_length parameter to optionally limit the length of the samples. \n",
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    " \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    " \n",
    "        mask = targets == pad_token_id   #Replace all but the first padding tokens in targets by ignore_index\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    " \n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    " \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    " \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc490c95-f8e2-4d0e-a2a2-7003941f8450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1044fd6c-f39f-4f70-a061-b7de1a5a5792",
   "metadata": {},
   "source": [
    "There are two approaches with the target text:\n",
    "- Masking the instruction tokens (instruction + input) and keep only the response. The idea is to train the model to focus on generating responses rather than memorizing instructions.\n",
    "- Don't mask the instructions.\n",
    "\n",
    "Researchers are divided bon whether masking the instructions is universally benficial. We will try and compare both approaches.\n",
    "Reference: https://arxiv.org/abs/2405.14394"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec30ee9a-6cac-41f5-9e0f-b4f8c0d9f00e",
   "metadata": {},
   "source": [
    "***3. Creating the data loaders***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d27d038c-896b-443b-8475-899c474f5f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\"\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f25fe61-6925-4a9d-9708-e818c1b38373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15e65939-7637-4755-9200-99ceae676aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab30a301-16f4-49d9-a0ec-f409d91d410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3352b59d-04d7-48ca-8ec7-8561d16e93b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "848a76a0-a374-481e-b8c6-1c5994ee375f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63c7add4-cb87-427a-ab57-a872ec44a8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e61b2d8-4e09-420c-b327-6964a97bb292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf02e73-df61-4210-a809-c281d91e6eba",
   "metadata": {},
   "source": [
    "***4) Loading pretrained LLM***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6451bf4c-baed-4a83-84f9-6632c66acd53",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'calc_accuracy_loader' from 'Classes' (C:\\Users\\lcast\\OneDrive\\Documents\\GitHub\\LLMs\\Finetuning_to_follow_instructions\\Classes.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mClasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPTModel,load_weights_into_gpt,generate,text_to_token_ids,token_ids_to_text, calc_accuracy_loader,calc_loss_loader, train_model_simple, plot_losses\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_download\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download_and_load_gpt2\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'calc_accuracy_loader' from 'Classes' (C:\\Users\\lcast\\OneDrive\\Documents\\GitHub\\LLMs\\Finetuning_to_follow_instructions\\Classes.py)"
     ]
    }
   ],
   "source": [
    "from Classes import GPTModel,load_weights_into_gpt,generate,text_to_token_ids,token_ids_to_text, calc_accuracy_loader,calc_loss_loader, train_model_simple, plot_losses\n",
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ae31593-04fc-4d15-8c7f-e6114ddd3b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\355M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\355M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    " \n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    " \n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    " \n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    " \n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42381b2-b457-4836-b71f-466f4257d8d8",
   "metadata": {},
   "source": [
    "First, we will assess the pretrained LLM without finetunning to obtain a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc29cdb0-bd38-4c5c-8d30-5a90c5f8bde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68a58bf0-f388-4dc8-9a7c-ab75012e7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4553ba8d-add4-40e2-bc55-0c67ac3487dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()#remocing the input text\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b945066-1c69-41b2-a72c-705f405b98c8",
   "metadata": {},
   "source": [
    "The model is not able to follow the instruction. It seems is just copying the instruction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6e615-a4cb-40f9-b766-a4d1f2ff12d7",
   "metadata": {},
   "source": [
    "***5) Finetunning the LLM on instruction data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e22fe82e-8994-4f12-8f6b-7ba7ff95db5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.825910139083862\n",
      "Validation loss: 3.761934280395508\n"
     ]
    }
   ],
   "source": [
    "#Calculating the initial loss for the training and validation sets\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    " \n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    " \n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4125b15-8deb-46a0-b70c-5ccc18a6684e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.102\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
      "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
      "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.532, Val loss 0.729\n",
      "Ep 1 (Step 000075): Train loss 0.569, Val loss 0.728\n",
      "Ep 1 (Step 000080): Train loss 0.605, Val loss 0.725\n",
      "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.709\n",
      "Ep 1 (Step 000090): Train loss 0.562, Val loss 0.691\n",
      "Ep 1 (Step 000095): Train loss 0.501, Val loss 0.682\n",
      "Ep 1 (Step 000100): Train loss 0.503, Val loss 0.677\n",
      "Ep 1 (Step 000105): Train loss 0.564, Val loss 0.670\n",
      "Ep 1 (Step 000110): Train loss 0.555, Val loss 0.666\n",
      "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.664\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.672\n",
      "Ep 2 (Step 000125): Train loss 0.451, Val loss 0.686\n",
      "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
      "Ep 2 (Step 000135): Train loss 0.405, Val loss 0.681\n",
      "Ep 2 (Step 000140): Train loss 0.409, Val loss 0.681\n",
      "Ep 2 (Step 000145): Train loss 0.368, Val loss 0.681\n",
      "Ep 2 (Step 000150): Train loss 0.382, Val loss 0.675\n",
      "Ep 2 (Step 000155): Train loss 0.413, Val loss 0.675\n",
      "Ep 2 (Step 000160): Train loss 0.415, Val loss 0.683\n",
      "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.685\n",
      "Ep 2 (Step 000170): Train loss 0.323, Val loss 0.681\n",
      "Ep 2 (Step 000175): Train loss 0.337, Val loss 0.669\n",
      "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.656\n",
      "Ep 2 (Step 000185): Train loss 0.415, Val loss 0.657\n",
      "Ep 2 (Step 000190): Train loss 0.341, Val loss 0.648\n",
      "Ep 2 (Step 000195): Train loss 0.329, Val loss 0.635\n",
      "Ep 2 (Step 000200): Train loss 0.310, Val loss 0.635\n",
      "Ep 2 (Step 000205): Train loss 0.352, Val loss 0.631\n",
      "Ep 2 (Step 000210): Train loss 0.367, Val loss 0.630\n",
      "Ep 2 (Step 000215): Train loss 0.395, Val loss 0.634\n",
      "Ep 2 (Step 000220): Train loss 0.302, Val loss 0.648\n",
      "Ep 2 (Step 000225): Train loss 0.348, Val loss 0.661\n",
      "Ep 2 (Step 000230): Train loss 0.295, Val loss 0.656\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 12.83 minutes.\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "import time\n",
    " \n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    " \n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    " \n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09d4150d-6220-42b2-94ab-4402a9f55df7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MaxNLocator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, num_epochs, \u001b[38;5;28mlen\u001b[39m(train_losses))\n\u001b[1;32m----> 2\u001b[0m plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
      "File \u001b[1;32m~\\LLMs\\LLMs\\Finetuning_to_follow_instructions\\Classes.py:432\u001b[0m, in \u001b[0;36mplot_losses\u001b[1;34m(epochs_seen, tokens_seen, train_losses, val_losses)\u001b[0m\n\u001b[0;32m    430\u001b[0m ax1\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    431\u001b[0m ax1\u001b[38;5;241m.\u001b[39mlegend(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper right\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 432\u001b[0m ax1\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mset_major_locator(MaxNLocator(integer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))  \u001b[38;5;66;03m# only show integer labels on x-axis\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# Create a second x-axis for tokens seen\u001b[39;00m\n\u001b[0;32m    435\u001b[0m ax2 \u001b[38;5;241m=\u001b[39m ax1\u001b[38;5;241m.\u001b[39mtwiny()  \u001b[38;5;66;03m# Create a second x-axis that shares the same y-axis\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MaxNLocator' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810c8563-e326-4da7-8e5b-7f3f5723a4f0",
   "metadata": {},
   "source": [
    "The generated responses are correct. The loss curves also indicate that the model's performance on both training and validation sets improve over the training, specially during the initial pahse of training, \n",
    "However, the most crucial aspect is the response quality and correctness, which need to be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139259fa-2a2f-4ba9-95e9-14f27d06a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further work\n",
    "#Using other kind of prompting\n",
    "#Use alpaca dataset his dataset contains 52,002 entries, which is approximately 50 times more than those we used in this chapter, and most entries are longer as well. Thus, it's highly recommended to conduct the training using a GPU to accelerate the finetuning process. If you encounter out-of-memory errors, consider reducing the batch_size from 8 to 4, 2, or even 1. Additionally, lowering the allowed_max_length from 1024 to 512 or 256 can further help manage memory issues.\n",
    "#Evaluate model using Open AI rather than Llama 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb61353-b90f-4713-9bd4-537db68a4797",
   "metadata": {},
   "source": [
    "***6) Evaluating the LLM***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78fc8ef8-4f37-4adf-831c-9a502d8abf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Gnerating responses for the three first instructions and comparing agains the true responses\n",
    "torch.manual_seed(123)\n",
    " \n",
    "for entry in test_data[:3]: \n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate( \n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    " \n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e857cec7-1906-4164-ba24-1e02f7a3a06e",
   "metadata": {},
   "source": [
    "The models seems to perform relatively we. The first and third are correct. The second one is partially correct because answers cumulus cloud vs cumulomimbus, which is not exactly the same.\n",
    "\n",
    "Inspect all instructions this way would be too time consuming. We will use an approach inspired vy AlpacaEval (https://tatsu-lab.github.io/alpaca_eval/) to leverage another LLM to evaluate our model's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf648d7c-613c-4531-b511-87aba82c082d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 110/110 [01:44<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "#Generating the responses of the test set and add them to the test_set file\n",
    "from tqdm import tqdm\n",
    " \n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    " \n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    " \n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35d5614e-435d-4c4b-9d2b-2a530a130abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a cheetah.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2df88115-d68b-46f8-bf3b-4a9fab4f1f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "#Saving model\n",
    "import re\n",
    " \n",
    "# Remove white spaces and parentheses from file name\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n",
    "#The saved model can then be loaded via model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0af95ae-215a-4df6-b13c-01a9d35550ab",
   "metadata": {},
   "source": [
    "We will use LLama 3 8B via Ollama to evaluate our LLM (ollama run llama3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99e43d36-1f95-4088-b37f-476b6812677d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "#After initiating Ollama3 we verify that is running\n",
    "import psutil\n",
    " \n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    " \n",
    "ollama_running = check_if_running(\"ollama\")\n",
    " \n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbd29dbf-47a8-48e8-aead-2de9c5d3764a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo load the model\\nimport json\\nfrom tqdm import tqdm\\n \\nfile_path = \"instruction-data-with-response.json\"\\nwith open(file_path, \"r\") as file:\\n    test_data = json.load(file)\\n \\ndef format_input(entry):\\n    instruction_text = (\\n        f\"Below is an instruction that describes a task. \"\\n        f\"Write a response that appropriately completes the request.\"\\n        f\"\\n\\n### Instruction:\\n{entry[\\'instruction\\']}\"\\n    )\\n \\n    input_text = f\"\\n\\n### Input:\\n{entry[\\'input\\']}\" if entry[\"input\"] else \"\"\\n       return instruction_text + input_text\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the saved model\n",
    "'''\n",
    "import json\n",
    "from tqdm import tqdm\n",
    " \n",
    "file_path = \"instruction-data-with-response.json\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    test_data = json.load(file)\n",
    " \n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    " \n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "       return instruction_text + input_text\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "466c8d97-a5c4-4b44-a18c-d00eefe1e7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily eat plants and plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
      "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet.\n",
      "3. Grains: Llamas may be fed grains like oats, barley, or corn as a supplement to their diet.\n",
      "4. Fruits and vegetables: Fresh fruits and vegetables, such as apples, carrots, and sweet potatoes, can be given as treats or added to their regular feed.\n",
      "5. Leaves: Llamas will also eat leaves from trees and shrubs, including plants like clover and alfalfa.\n",
      "\n",
      "In the wild, llamas may eat a wider variety of plants, including:\n",
      "\n",
      "* Shrubbery\n",
      "* Vines\n",
      "* Mushrooms\n",
      "* Bark (in some cases)\n",
      "\n",
      "Domesticated llamas are typically fed a diet that is designed to meet their nutritional needs, which includes a balanced mix of protein, fiber, and other essential nutrients. A good quality llama feed or a combination of hay, grains, and fruits/vegetables can provide the necessary nutrition for these lovely animals!\n"
     ]
    }
   ],
   "source": [
    "#Function to interact with Ollama via REST API\n",
    "\n",
    "import urllib.request\n",
    " \n",
    "def query_model(prompt, model=\"llama3\", url=\"http://localhost:11434/api/chat\"):\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"seed\": 123,        # for deterministic responses\n",
    "        \"temperature\": 0,   # for deterministic responses\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    " \n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "    request = urllib.request.Request(url, data=payload, method=\"POST\")\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    " \n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    " \n",
    "    return response_data\n",
    " \n",
    "\n",
    "model = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\", model)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3e89e21-14dc-469b-937b-e6d1ddfb4009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "\n",
      "Score:\n",
      ">> To evaluate the model's response, I'll compare it to the desired output.\n",
      "\n",
      "Desired output: The car is as fast as lightning.\n",
      "Model response: The car is as fast as a cheetah.\n",
      "\n",
      "Similarity metrics:\n",
      "\n",
      "* Both responses use a simile structure (\"as [adjective] as [comparable noun]\")\n",
      "* Lightning and a cheetah are both high-speed entities, which makes them comparable in this context\n",
      "* However, lightning is an extremely fast natural phenomenon (approximately 270,000 km/h), while a cheetah is a very fast animal (approximately 120 km/h)\n",
      "\n",
      "Score: 85\n",
      "\n",
      "The model's response is close to the desired output, but it doesn't quite match the level of speed and intensity conveyed by the original simile. While a cheetah is indeed fast, it's not as extreme an example as lightning. A score of 85 reflects the model's good attempt, but room for improvement in terms of creating an even more vivid and evocative comparison.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "\n",
      "Score:\n",
      ">> I would score this model response as 40 out of 100.\n",
      "\n",
      "Reasoning:\n",
      "\n",
      "* The response partially answers the question by mentioning that thunderstorms are associated with clouds.\n",
      "* However, it incorrectly identifies the type of cloud, stating that it's a cumulus cloud instead of cumulonimbus, which is the correct answer.\n",
      "* A good model response should provide accurate and precise information. In this case, the response does not meet this standard.\n",
      "\n",
      "To achieve a higher score, the model could improve by providing more accurate and specific information that aligns with the question being asked.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Score:\n",
      ">> I would score my own response as 95 out of 100. Here's why:\n",
      "\n",
      "* The prompt is simple and straightforward, asking for the author of 'Pride and Prejudice'.\n",
      "* My response is a direct answer to the question, accurately stating that Jane Austen is the author.\n",
      "* The response is clear and easy to understand, with no errors or ambiguities.\n",
      "\n",
      "The only reason I wouldn't score it as 100 out of 100 is that some models might respond with just \"Jane Austen\" without the additional phrase \"The author of 'Pride and Prejudice' is\". However, since my response includes both the question being answered and the correct answer, I believe it's a strong contender for a perfect score.\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "#Evluating the first entries\n",
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f3f1beb-54d8-46f6-80e8-75268a38a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asking for a numeric response only\n",
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    " \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5613f8ca-816d-49c5-8c6a-c98981cb8795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|| 110/110 [11:34<00:00,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 49.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Generating the results\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775d1a91-d20a-4940-87bf-147c82342935",
   "metadata": {},
   "source": [
    "***Variation 1:  Mask the instructions.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57e0e07d-a988-4e3f-bc58-1484b5356371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify yhe instruction class to collect the length of the instructions\n",
    "\n",
    "class InstructionDataset2(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.instruction_lengths=[]\n",
    "        self.encoded_texts = []\n",
    "        for entry in data: \n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "            instruction_length=len(tokenizer.encode(instruction_plus_input))\n",
    "            self.instruction_lengths.append(instruction_length)\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index],self.instruction_lengths[index]\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81db322e-5ce9-4b6a-8a9a-f95207ce00c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update collate function and now each batch is a tuple containg also the instruction length\n",
    "def custom_collate_fn2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item, instruction_length in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    " \n",
    "    for item, instruction_length in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    " \n",
    "        mask = targets == pad_token_id   #Replace all but the first padding tokens in targets by ignore_index\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        targets[:instruction_length-1]=-100 #Mask all instruction and inputs tokens\n",
    "        \n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    " \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    " \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4178ddf-272e-487d-af9c-c1868b16ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "customized_collate_fn2 = partial(\n",
    "    custom_collate_fn2,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "142a99a8-5713-49cb-819f-9e82b621aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset2(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn2,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "\n",
    "val_dataset = InstructionDataset2(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn2,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset2(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn2,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15a18f5b-76be-4cf0-8e35-0b86d608b4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\355M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\355M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    " \n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    " \n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    " \n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    " \n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1212a954-68da-483f-a577-00ebddfc657e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.3913220882415773\n",
      "Validation loss: 2.2625602960586546\n"
     ]
    }
   ],
   "source": [
    "#Calculating the initial loss for the training and validation sets\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    " \n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    " \n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6c7f821-d3d3-46d7-92f6-2378cc1d3eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 1.636, Val loss 1.620\n",
      "Ep 1 (Step 000005): Train loss 1.060, Val loss 1.026\n",
      "Ep 1 (Step 000010): Train loss 0.881, Val loss 0.939\n",
      "Ep 1 (Step 000015): Train loss 0.878, Val loss 0.903\n",
      "Ep 1 (Step 000020): Train loss 0.817, Val loss 0.878\n",
      "Ep 1 (Step 000025): Train loss 0.737, Val loss 0.847\n",
      "Ep 1 (Step 000030): Train loss 0.779, Val loss 0.825\n",
      "Ep 1 (Step 000035): Train loss 0.645, Val loss 0.806\n",
      "Ep 1 (Step 000040): Train loss 0.757, Val loss 0.804\n",
      "Ep 1 (Step 000045): Train loss 0.564, Val loss 0.801\n",
      "Ep 1 (Step 000050): Train loss 0.662, Val loss 0.789\n",
      "Ep 1 (Step 000055): Train loss 0.896, Val loss 0.786\n",
      "Ep 1 (Step 000060): Train loss 0.670, Val loss 0.773\n",
      "Ep 1 (Step 000065): Train loss 0.564, Val loss 0.759\n",
      "Ep 1 (Step 000070): Train loss 0.523, Val loss 0.758\n",
      "Ep 1 (Step 000075): Train loss 0.533, Val loss 0.753\n",
      "Ep 1 (Step 000080): Train loss 0.559, Val loss 0.744\n",
      "Ep 1 (Step 000085): Train loss 0.480, Val loss 0.738\n",
      "Ep 1 (Step 000090): Train loss 0.532, Val loss 0.726\n",
      "Ep 1 (Step 000095): Train loss 0.391, Val loss 0.717\n",
      "Ep 1 (Step 000100): Train loss 0.486, Val loss 0.698\n",
      "Ep 1 (Step 000105): Train loss 0.525, Val loss 0.703\n",
      "Ep 1 (Step 000110): Train loss 0.537, Val loss 0.692\n",
      "Ep 1 (Step 000115): Train loss 0.467, Val loss 0.682\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The U.S. government is considering a new policy to protect the privacy of U.S. citizens abroad.  The new policy would require the government to\n",
      "Ep 2 (Step 000120): Train loss 0.377, Val loss 0.681\n",
      "Ep 2 (Step 000125): Train loss 0.362, Val loss 0.690\n",
      "Ep 2 (Step 000130): Train loss 0.337, Val loss 0.707\n",
      "Ep 2 (Step 000135): Train loss 0.268, Val loss 0.720\n",
      "Ep 2 (Step 000140): Train loss 0.286, Val loss 0.737\n",
      "Ep 2 (Step 000145): Train loss 0.257, Val loss 0.741\n",
      "Ep 2 (Step 000150): Train loss 0.203, Val loss 0.736\n",
      "Ep 2 (Step 000155): Train loss 0.286, Val loss 0.755\n",
      "Ep 2 (Step 000160): Train loss 0.387, Val loss 0.758\n",
      "Ep 2 (Step 000165): Train loss 0.273, Val loss 0.739\n",
      "Ep 2 (Step 000170): Train loss 0.177, Val loss 0.731\n",
      "Ep 2 (Step 000175): Train loss 0.244, Val loss 0.721\n",
      "Ep 2 (Step 000180): Train loss 0.314, Val loss 0.709\n",
      "Ep 2 (Step 000185): Train loss 0.327, Val loss 0.714\n",
      "Ep 2 (Step 000190): Train loss 0.195, Val loss 0.711\n",
      "Ep 2 (Step 000195): Train loss 0.200, Val loss 0.702\n",
      "Ep 2 (Step 000200): Train loss 0.152, Val loss 0.699\n",
      "Ep 2 (Step 000205): Train loss 0.231, Val loss 0.696\n",
      "Ep 2 (Step 000210): Train loss 0.257, Val loss 0.694\n",
      "Ep 2 (Step 000215): Train loss 0.279, Val loss 0.688\n",
      "Ep 2 (Step 000220): Train loss 0.167, Val loss 0.696\n",
      "Ep 2 (Step 000225): Train loss 0.153, Val loss 0.700\n",
      "Ep 2 (Step 000230): Train loss 0.132, Val loss 0.702\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The new year is a time of great change and excitement. It is a time when new ideas and new ideas are born. It is a time when new ideas are\n",
      "Training completed in 13.29 minutes.\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "import time\n",
    " \n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    " \n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    " \n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba940ed8-0e62-474d-a4c1-873e13e8a554",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MaxNLocator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, num_epochs, \u001b[38;5;28mlen\u001b[39m(train_losses))\n\u001b[1;32m----> 2\u001b[0m plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\LLMs\\Finetuning_to_follow_instructions\\Classes.py:432\u001b[0m, in \u001b[0;36mplot_losses\u001b[1;34m(epochs_seen, tokens_seen, train_losses, val_losses)\u001b[0m\n\u001b[0;32m    430\u001b[0m ax1\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    431\u001b[0m ax1\u001b[38;5;241m.\u001b[39mlegend(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper right\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 432\u001b[0m ax1\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mset_major_locator(MaxNLocator(integer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))  \u001b[38;5;66;03m# only show integer labels on x-axis\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# Create a second x-axis for tokens seen\u001b[39;00m\n\u001b[0;32m    435\u001b[0m ax2 \u001b[38;5;241m=\u001b[39m ax1\u001b[38;5;241m.\u001b[39mtwiny()  \u001b[38;5;66;03m# Create a second x-axis that shares the same y-axis\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MaxNLocator' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdMAAAEmCAYAAAA5oXoHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABjCElEQVR4nO3dd3gU1frA8e9uyqYX0gNJaCEhlAChhCYgHUWKCnqpivpDFET0qugVQa8XUZGiguIFcm10QZQiRSB0BBKk10ACJIQkpJO68/tjyMKSENI3gffzPPOQTM7MvLsZ8u45c4pGURQFIYQQQpSZ1tQBCCGEEDWdJFMhhBCinCSZCiGEEOUkyVQIIYQoJ0mmQgghRDlJMhVCCCHKSZKpEEIIUU6STIUQQohyMjd1ANWRXq/n6tWr2Nvbo9FoTB2OEEIIE1EUhbS0NLy9vdFq713/lGRahKtXr+Lj42PqMIQQQlQTMTEx1KlT554/l2RaBHt7e0B98xwcHEwcjRBCCFNJTU3Fx8fHkBfuRZJpEQqadh0cHCSZCiGEuO8jP+mAJIQQQpSTJFMhhBCinCSZCiGEEOUkz0yFEDWOoijk5eWRn59v6lBEDWdmZoa5uXm5h0FKMhVC1Cg5OTnExsaSmZlp6lDEA8LGxgYvLy8sLS3LfA5JpkKIGkOv1xMVFYWZmRne3t5YWlrKxCqizBRFIScnh+vXrxMVFYW/v3+xEzMUR5JpJTkXn84byyOxMNOy8uUOpg5HiAdCTk4Oer0eHx8fbGxsTB2OeABYW1tjYWHBpUuXyMnJwcrKqkznkWRaSSzNtBy5nIKVhRZFUeTTsxAVqKy1ByGKUhH3k9yRlcTNXgdAVq6etOw8E0cjhBCiMknNtJJY56fxgW4J1vlpXE/rgoOVhalDEkIIUUmkZlpZNBqe0/zGM+bbSbyRbOpohBAPmK5duzJx4sQSl7948SIajYbIyMhKiwlg+/btaDQakpOTK/U61Y3UTCuLzoEcLLEkh9SEq9Do3qsNCCEeXPfrLzFq1CjCwsJKfd5ffvkFC4uSt3j5+PgQGxuLq6trqa8l7k+SaWXRaEg1r4VrXhyZN2JNHY0QwkRiY2///1+2bBlTpkzh9OnThn3W1tZG5XNzc0uUJGvVqlWqOMzMzPD09CzVMaLkpJm3EmXpXADISZZkKkRlURSFzJy8Kt8URSlRfJ6enobN0dERjUZj+D4rKwsnJyeWL19O165dsbKy4scffyQxMZFnn32WOnXqYGNjQ7NmzViyZInRee9u5q1bty7/+c9/eP7557G3t8fX15cFCxYYfn53M29Bc+zWrVtp3bo1NjY2dOjQwSjRA/z73//G3d0de3t7XnjhBd555x1atGhRqt/RqlWraNKkCTqdjrp16zJz5kyjn8+bNw9/f3+srKzw8PDgqaeeMvxs5cqVNGvWDGtra1xcXOjRowcZGRmlun5VkJppJcq1coMMUNKumToUIR5YN3PzCZryR5Vf98SHvbGxrJg/oW+//TYzZ85k8eLF6HQ6srKyCAkJ4e2338bBwYF169YxYsQI6tevT7t27e55npkzZ/LRRx/x7rvvsnLlSl5++WUeeeQRAgMD73nMe++9x8yZM3Fzc2Ps2LE8//zz7N69G4CffvqJjz/+mHnz5tGxY0eWLl3KzJkzqVevXolf26FDhxgyZAhTp05l6NCh7Nmzh3HjxuHi4sLo0aM5ePAgEyZM4IcffqBDhw4kJSWxc+dOQK3VP/vss3z66acMGjSItLQ0du7cWeIPMlVJkmklUmzdIBHMMq+bOhQhRDU2ceJEBg8ebLTvzTffNHw9fvx4Nm7cyIoVK4pNpv369WPcuHGAmqBnzZrF9u3bi02mH3/8MV26dAHgnXfe4bHHHiMrKwsrKyu+/PJLxowZw3PPPQfAlClT2LRpE+np6SV+bV988QXdu3fn/fffB6BRo0acOHGCzz77jNGjRxMdHY2trS2PP/449vb2+Pn50bJlS0BNpnl5eQwePBg/Pz8AmjVrVuJrVyVJppVI6+ABgGVWgokjEeLBZW1hxokPe5vkuhWldevWRt/n5+fzySefsGzZMq5cuUJ2djbZ2dnY2toWe57mzZsbvi5oTo6Pjy/xMV5eXgDEx8fj6+vL6dOnDcm5QNu2bfnzzz9L9LoATp48yYABA4z2dezYkdmzZ5Ofn0/Pnj3x8/Ojfv369OnThz59+jBo0CBsbGwIDg6me/fuNGvWjN69e9OrVy+eeuopnJ2dS3z9qiLPTCuRlZP6sN8mJ9HEkQjx4NJoNNhYmlf5VpGzmt2dJGfOnMmsWbN46623+PPPP4mMjKR3797k5OQUe567Oy5pNBr0en2Jjyl4TXcec/frLG0Ta1EzwN15Dnt7ew4fPsySJUvw8vJiypQpBAcHk5ycjJmZGZs3b2bDhg0EBQXx5ZdfEhAQQFRUVKliqAqSTCuRTS1vABz1N8jNL/6GFkKIAjt37mTAgAEMHz6c4OBg6tevz9mzZ6s8joCAAA4cOGC07+DBg6U6R1BQELt27TLat2fPHho1aoSZmVq7Nzc3p0ePHnz66af8/fffXLx40VD71Wg0dOzYkWnTphEREYGlpSWrV68ux6uqHNLMW4nsXGoD4EYyiek5eDqWbQJlIcTDpWHDhqxatYo9e/bg7OzMF198QVxcHI0bN67SOMaPH8+LL75I69at6dChA8uWLePvv/+mfv36JT7HG2+8QZs2bfjoo48YOnQoe/fu5auvvmLevHkA/P7771y4cIFHHnkEZ2dn1q9fj16vJyAggP3797N161Z69eqFu7s7+/fv5/r161X+PpSEJNNKpLV3B8BVk8r51CxJpkKIEnn//feJioqid+/e2NjY8NJLLzFw4EBSUlKqNI5hw4Zx4cIF3nzzTbKyshgyZAijR48uVFstTqtWrVi+fDlTpkzho48+wsvLiw8//JDRo0cD4OTkxC+//MLUqVPJysrC39+fJUuW0KRJE06ePEl4eDizZ88mNTUVPz8/Zs6cSd++fSvpFZedRqmOfYxNLDU1FUdHR1JSUnBwcCj7ibLTYbpaO90++DBdmzeooAiFeDhlZWURFRVFvXr1yrxUliifnj174unpyQ8//GDqUCpMcfdVSfOBSZ+ZhoeH079/f7y9vdFoNKxZs6bY8gWDjO/eTp06ZVRu1apVBAUFodPpCAoKMl37us6OY1Yh/J7fjqTUknclF0KI6iAzM5MvvviC48ePc+rUKT744AO2bNnCqFGjTB1atWPSZJqRkUFwcDBfffVVqY47ffo0sbGxhs3f39/ws7179zJ06FBGjBjBkSNHGDFiBEOGDGH//v0VHX6J/NBwNq/mvsaVbFnIWAhRs2g0GtavX0/nzp0JCQnht99+Y9WqVfTo0cPUoVU7Jn1m2rdv3zK1fbu7u+Pk5FTkz2bPnk3Pnj2ZPHkyAJMnT2bHjh3Mnj270HRcVcHdQV3XND4tu8qvLYQQ5WFtbc2WLVtMHUaNUCOHxrRs2RIvLy+6d+/Otm3bjH62d+9eevXqZbSvd+/e7Nmz557ny87OJjU11WirKG72OjTouZGaVmHnFEIIUb3UqGTq5eXFggULWLVqFb/88gsBAQF0796d8PBwQ5m4uDg8PDyMjvPw8CAuLu6e550+fTqOjo6GzcfHp8Ji7njxK87qRtIlLqzCzimEEKJ6qVFDYwICAggICDB83759e2JiYvj888955JFHDPuLmm2juNlKJk+ezKRJkwzfp6amVlhCtbKxw1yjxypbphQUQogHVY1KpkUJDQ3lxx9/NHzv6elZqBYaHx9fqLZ6J51Oh06nq5T4lJAxtNvbgAwLJx6/T1IXQghRM9WoZt6iREREGCZnBrW2unnzZqMymzZtokOHDlUdGgAu7t5coxbpuVrSsvNMEoMQQojKZdJkmp6eTmRkpGGx2qioKCIjI4mOjgbU5teRI0cays+ePZs1a9Zw9uxZjh8/zuTJk1m1ahWvvvqqocxrr73Gpk2bmDFjBqdOnWLGjBls2bLFaBHdqmRtaYa9Tm0AuC49eoUQZVTUYuCzZ88u9piSjN8viYo6T3GmTp1a6kXHqxOTNvMePHiQbt26Gb4veG45atQowsLCiI2NNSRWgJycHN58802uXLmCtbU1TZo0Yd26dfTr189QpkOHDixdupR//etfvP/++zRo0IBly5YVuwZgpcpO433LnzDTJxKf0o4GbnamiUMIYRL9+/fn5s2bRQ4x2bt3Lx06dODQoUO0atWqVOf966+/7rskW2lNnTqVNWvWGCo4BWJjY6vlsmfViUmTadeuXYtdzicsLMzo+7feeou33nrrvud96qmneOqpp8obXsXQWjAk91cwgw03rgOupo5ICFGFxowZw+DBg7l06ZJhgesCixYtokWLFqVOpABubm4VFeJ9eXp6Vtm1aqoa/8y02rOwIlOrfnrMSIo1cTBCiKr2+OOP4+7uXqhykJmZybJlyxgzZgyJiYk8++yz1KlTBxsbG5o1a3bfSWbubuY9e/YsjzzyCFZWVgQFBRXqOwLw9ttv06hRI2xsbKhfvz7vv/8+ubm5gFp5mTZtGkeOHDFM1VoQ893NvEePHuXRRx/F2toaFxcXXnrpJdLTb0+ZOnr0aAYOHMjnn3+Ol5cXLi4uvPLKK4ZrlYRer+fDDz+kTp066HQ6WrRowcaNGw0/z8nJ4dVXX8XLywsrKyvq1q3L9OnTDT+fOnUqvr6+6HQ6vL29mTBhQomvXRY1vjdvTZBp4YJNdgbZyVdNHYoQD66cjNIfY6YDs1t/BvPzID8bNFqwsC7+vJYlb141Nzdn5MiRhIWFMWXKFEOP/hUrVpCTk8OwYcPIzMwkJCSEt99+GwcHB9atW8eIESOoX79+iR5R6fV6Bg8ejKurK/v27SM1NbXIfiL29vaEhYXh7e3N0aNHefHFF7G3t+ett95i6NChHDt2jI0bNxqapB0dHQudIzMzkz59+hAaGspff/1FfHw8L7zwAq+++qrRB4Zt27bh5eXFtm3bOHfuHEOHDqVFixa8+OKLJXrf5syZw8yZM/n2229p2bIlixYt4oknnuD48eP4+/szd+5c1q5dy/Lly/H19SUmJoaYmBgAVq5cyaxZs1i6dClNmjQhLi6OI0eOlOi6ZSXJtArkWLlCdjT5qddMHYoQD67/eJf+mKfDoMkg9etTv8GK0eDXCZ5bd7vM7GaQmWh83NTSLYX2/PPP89lnn7F9+3ZDP5FFixYxePBgnJ2dcXZ25s033zSUHz9+PBs3bmTFihUlSqZbtmzh5MmTXLx4kTp16gDwn//8p9B0rf/6178MX9etW5c33niDZcuW8dZbb2FtbY2dnR3m5ubFNuv+9NNP3Lx5k++//97wzParr76if//+zJgxwzAM0dnZma+++gozMzMCAwN57LHH2Lp1a4mT6eeff87bb7/NM888A8CMGTPYtm0bs2fP5uuvvyY6Ohp/f386deqERqMxakKPjo7G09OTHj16YGFhga+vL23bti3RdctKmnmrQL6tuq6pJuO6iSMRQphCYGAgHTp0YNGiRQCcP3+enTt38vzzzwOQn5/Pxx9/TPPmzXFxccHOzo5NmzYZdcAszsmTJ/H19TUkUlCHCd5t5cqVdOrUCU9PT+zs7Hj//fdLfI07rxUcHGzU+aljx47o9XpOnz5t2NekSRPMzMwM33t5eREfH1+ia6SmpnL16lU6duxotL9jx46cPHkSUJuSIyMjCQgIYMKECWzatMlQ7umnn+bmzZvUr1+fF198kdWrV5OXV7lDE6VmWgW0duonNcubkkyFqDTvluExitkdk7UE9lfPobmrjjHxaPniumXMmDG8+uqrfP311yxevBg/Pz+6d+8OwMyZM5k1axazZ8+mWbNm2NraMnHiRHJyckp07qI6ct49Qcy+fft45plnmDZtGr1798bR0ZGlS5cyc+bMUr2O4maUu3O/hYVFoZ/p9fpSXau42exatWpFVFQUGzZsYMuWLQwZMoQePXqwcuVKfHx8OH36NJs3b2bLli2MGzeOzz77jB07dhSKq6JIzbQKWDiqydQ6J/E+JYUQZWZpW/rN7I76hJm5uu/O56X3Om8ZDBkyBDMzM37++Wf+97//8dxzzxkSw86dOxkwYADDhw8nODiY+vXrc/bs2RKfOygoiOjoaK5evf2BYu/evUZldu/ejZ+fH++99x6tW7fG39+fS5cuGb9US0vy8/Pve63IyEgyMm4/S969ezdarZZGjRqVOObiODg44O3tza5du4z279mzh8aNGxuVGzp0KN999x3Lli1j1apVJCUlAeqKN0888QRz585l+/bt7N27l6NHK+aDUVGkZloFrGupz3Ls85LIzddjYSafYYR42NjZ2TF06FDeffddUlJSGD16tOFnDRs2ZNWqVezZswdnZ2e++OIL4uLijBJHcXr06EFAQAAjR45k5syZpKam8t577xmVadiwIdHR0SxdupQ2bdqwbt06Vq9ebVSmbt26hslz6tSpg729faGpVocNG8YHH3zAqFGjmDp1KtevX2f8+PGMGDGi2GlbS+uf//wnH3zwAQ0aNKBFixYsXryYyMhIfvrpJwBmzZqFl5cXLVq0QKvVsmLFCjw9PXFyciIsLIz8/HzatWuHjY0NP/zwA9bW1oWGJlUk+ateBWyd1ekO3TQpJKaXrNlGCPHgGTNmDDdu3KBHjx74+voa9r///vu0atWK3r1707VrVzw9PRk4cGCJz6vValm9ejXZ2dm0bduWF154gY8//tiozIABA3j99dd59dVXadGiBXv27OH99983KvPkk0/Sp08funXrhpubW5HDc2xsbPjjjz9ISkqiTZs2PPXUU3Tv3p2vvvqqdG/GfUyYMIE33niDN954g2bNmrFx40bWrl2Lv78/oH44mTFjBq1bt6ZNmzZcvHiR9evXo9VqcXJy4rvvvqNjx440b96crVu38ttvv+Hi4lKhMd5JoxQ3a8JDKjU1FUdHR1JSUnBwcCj/Ca9GwIKuXFOcuPbiEZrXcSr/OYV4CGVlZREVFUW9evWwsrIydTjiAVHcfVXSfCA106pwqzevC6lcT71p4mCEEEJUNEmmVcFWnfbLXKMnNVHGmgohxINGOiBVBXNLTth35HxyPonpUjMVQogHjdRMq8iGZrMYnzuBS9n2pg5FCCFEBZNkWkXc7NXu5fFpWSaORAghREWTZFpF3Ox0aNGTkppq6lCEqPFkEIKoSBVxP0kyrSLB5+dxVjeCATfCTB2KEDVWwVRwmZmZJo5EPEgK7qfyTDUoHZCqiLWNA2YaBeucpGLnthRC3JuZmRlOTk6GCdNtbGzk/5IoM0VRyMzMJD4+HicnJ6OJ+UtLkmkVsWr3PG3+9CIJBx7NzsPBqnImWxbiQVewPFhJVyAR4n6cnJyKXXauJCSZVhFrRxeydG7kZ+dxPS1bkqkQZaTRaPDy8sLd3Z3c3FxThyNqOAsLi3LVSAtIMq1CbvY60rLziE/NpoGbnanDEaJGMzMzq5A/gkJUBEmmVSX3Jm8oYeRZXCMhtRlQeRMuCyGEqFqSTKuKmSV9M35Fa6bnp8Q4wPe+hwghhKgZZGhMVdGakWnuBEBWcqxpYxFCCFGhJJlWoSyd2rSblyqT3QshxIPEpMk0PDyc/v374+3tjUajYc2aNcWW/+WXX+jZsydubm44ODjQvn17/vjjD6MyYWFhaDSaQltWlumn8cuzUVePIV2SqRBCPEhMmkwzMjIIDg4u8Qrt4eHh9OzZk/Xr13Po0CG6detG//79iYiIMCrn4OBAbGys0VYdFhLW2HkAYJaZYOJIhBBCVCSTdkDq27cvffv2LXH52bNnG33/n//8h19//ZXffvuNli1bGvZrNJpyD8CtDOYOajK1ypZkKoQQD5Ia/cxUr9eTlpZGrVq1jPanp6fj5+dHnTp1ePzxxwvVXO+WnZ1Namqq0VYZdM5eANjnJZGbr6+UawghhKh6NTqZzpw5k4yMDIYMGWLYFxgYSFhYGGvXrmXJkiVYWVnRsWNHzp49e8/zTJ8+HUdHR8Pm4+NTKfHaOHsD4EoKiek5lXINIYQQVa/GJtMlS5YwdepUli1bhru7u2F/aGgow4cPJzg4mM6dO7N8+XIaNWrEl19+ec9zTZ48mZSUFMMWExNTKTFr7dU43TTJsq6pEEI8QGrkpA3Lli1jzJgxrFixgh49ehRbVqvV0qZNm2JrpjqdDp1OV9FhFnarA5KbJoXDadmVfz0hhBBVosbVTJcsWcLo0aP5+eefeeyxx+5bXlEUIiMj8fLyqoLo7sNWrZk6a9JJSEk3cTBCCCEqiklrpunp6Zw7d87wfVRUFJGRkdSqVQtfX18mT57MlStX+P777wE1kY4cOZI5c+YQGhpKXFwcANbW1jg6OgIwbdo0QkND8ff3JzU1lblz5xIZGcnXX39d9S/wbtbO5GOGGflkJMUCDUwdkRBCiApg0prpwYMHadmypWFYy6RJk2jZsiVTpkwBIDY2lujoaEP5b7/9lry8PF555RW8vLwM22uvvWYok5yczEsvvUTjxo3p1asXV65cITw8nLZt21btiyuKVss5ly78mt9BOiAJIcQDRKMoimLqIKqb1NRUHB0dSUlJwcHBoULP/f3ei0z59Ti9m3jw7YjWFXpuIYQQFauk+aDGPTOt6dzt1Y5O16UDkhBCPDAkmVYxN3sdZuSTUkkTQwghhKh6kkyrWIOT8zmrG8mozDCkhV0IIR4MkkyrmI29M1qNQi0lmbTsPFOHI4QQogLUyEkbajLLkGF02eRKTK41m1KzcbCyMHVIQgghyklqplXNyhEze3f0aKUTkhBCPCAkmZqAW0GP3nRJpkII8SCQZFrV8nIYe3MBX1nMJfFGsqmjEUIIUQEkmVY1Mws6p/zG42b7uJkca+pohBBCVABJplVNo+GmpQsAuclxJg5GCCFERZBkagK51m4A6NPjTRyJEEKIiiDJ1AQUWzWZmmVIMhVCiAeBJFMT0Np7AmCRlWjiSIQQQlQESaYmoHNSk6ldbiK5+XoTRyOEEKK8JJmagJWzFwBumhQSZKypEELUeJJMTUBr7wGAqyZFZkESQogHgCRTU7B1B8CNZEmmQgjxAJBkagp2ajJ11aQQL8lUCCFqPEmmpmCnNvPaarJJTr5h4mCEEEKUlyRTU9DZkau1AiD5+hUTByOEEKK8ZD1TE0ny7c2e8wnsjUpGr1fQajWmDkkIIUQZSc3URJyGL+Z97Wv8ne7IkcvJpg5HCCFEOUgyNRGduRldAtRpBbecvGbiaIQQQpSHJFMT6hVQC1tusuWEzNErhBA1mUmTaXh4OP3798fb2xuNRsOaNWvue8yOHTsICQnBysqK+vXr88033xQqs2rVKoKCgtDpdAQFBbF69epKiL6c9s1nwG/BrLKcyrlryUQnZpo6IiGEEGVk0mSakZFBcHAwX331VYnKR0VF0a9fPzp37kxERATvvvsuEyZMYNWqVYYye/fuZejQoYwYMYIjR44wYsQIhgwZwv79+yvrZZRN06fAygmsHHAinc3S1CuEEDWWRlEUxdRBAGg0GlavXs3AgQPvWebtt99m7dq1nDx50rBv7NixHDlyhL179wIwdOhQUlNT2bBhg6FMnz59cHZ2ZsmSJSWKJTU1FUdHR1JSUnBwcCjbCyqJhLMsPKnlo3WnCK1fi6Uvta+8awkhhCi1kuaDGvXMdO/evfTq1ctoX+/evTl48CC5ubnFltmzZ889z5udnU1qaqrRViVc/ekZpE56/9fFGyRn5lTNdYUQQlSoGpVM4+Li8PDwMNrn4eFBXl4eCQkJxZaJi4u753mnT5+Oo6OjYfPx8an44O/B18WGYHdz3tV+z7kti6rsukIIISpOjUqmoDYH36mglfrO/UWVuXvfnSZPnkxKSophi4mJqcCI7++1WvsYY76BwMiPIUMWDBdCiJqmRiVTT0/PQjXM+Ph4zM3NcXFxKbbM3bXVO+l0OhwcHIy2qlSr2zhO6n2w06eSv3FylV5bCCFE+dWoZNq+fXs2b95stG/Tpk20bt0aCwuLYst06NChyuIsreY+rnxqMQ69osHs6DI4t9XUIQkhhCgFkybT9PR0IiMjiYyMBNShL5GRkURHRwNq8+vIkSMN5ceOHculS5eYNGkSJ0+eZNGiRSxcuJA333zTUOa1115j06ZNzJgxg1OnTjFjxgy2bNnCxIkTq/KllYpWq8GzSWf+l3+r49Tvr0OOjDsVQoiaokzJNCYmhsuXLxu+P3DgABMnTmTBggWlOs/Bgwdp2bIlLVu2BGDSpEm0bNmSKVOmABAbG2tIrAD16tVj/fr1bN++nRYtWvDRRx8xd+5cnnzySUOZDh06sHTpUhYvXkzz5s0JCwtj2bJltGvXriwvtcr0DHLn87whxOEKyZdg+3RThySEEKKEyjTOtHPnzrz00kuMGDGCuLg4AgICaNKkCWfOnGHChAmGZFhTVdk40ztk5ebT8sPNtM//i0WWn4PGDF7aBl7BVXJ9IYQQhVXqONNjx47Rtm1bAJYvX07Tpk3Zs2cPP//8M2FhYWUK+GFnZWHGI41c+VPfitMuPUDJh7XjISfD1KEJIYS4jzIl09zcXHQ6HQBbtmzhiSeeACAwMJDY2NiKi+4h0zPIE4AP80aBlSPEHoFvOsGlvSaOTAghRHHKlEybNGnCN998w86dO9m8eTN9+vQB4OrVq4YhKqL0ugW4odXA7mtmXH88DBxqQ9IFWNwXNk6G/FxThyiEEKIIZUqmM2bM4Ntvv6Vr1648++yzBAerz/XWrl1raP4VpedipyPEzxmADWn1YdxeaDkcUCApCrTmpg1QCCFEkcr017lr164kJCSQmpqKs7OzYf9LL72EjY1NhQX3MOoZ5MFfF2+w+cQ1RravCwO+hqCB4NkMCmZxykoFMwuwsDZlqEIIIW4pU8305s2bZGdnGxLppUuXmD17NqdPn8bd3b1CA3zY9GisztS070IiqVm3mnX9e4K95+1C6/+pPku9dtwEEQohhLhbmZLpgAED+P777wFITk6mXbt2zJw5k4EDBzJ//vwKDfBhU9/NjgZutuTmK+w4fb1wgYxEiNoBiefU4TMPkXPx6ey7IHMXCyGqnzIl08OHD9O5c2cAVq5ciYeHB5cuXeL7779n7ty5FRrgw6hHkFo73VLUguG2Luqz1H6fg3vg7f0bJ8OOTyEjoYqirFqKojBq0QH+8d0+zsWnmTocIYQwUqZnppmZmdjb2wPqvLeDBw9Gq9USGhrKpUuXKjTAh1HPxh58u+MCf56KZ3XEZWwtzbHTmWNnZY6tzhw7nTV2wc9hW3BA6lU4sAD0eRD+OTQfAqEvg0cTU76MCnUhIYMryTcB2H0ukYbu9iaOSAghbitTMm3YsCFr1qxh0KBB/PHHH7z++uuAujpLVa+48iBq6euMq50lCek5vL7syD3LPRrozrxhrbCydYNB38Ler+HqYYj4Qd0aPwG9PgLnulUXfCU5eDHJ8PWBqCRGdahrumCEEOIuZWrmnTJlCm+++SZ169albdu2tG/fHlBrqQXz7IqyM9NqmPFkc/o08aRTQ1da+Djh726Hl6MV9lbmaG916v3zVDwTlkSQrzGHZk/Bi3/C85vU3r8aLZxcC1+1hS3TILtmN43+dfGG4ev9UYmUYRZMIYSoNGWamxcgLi6O2NhYgoOD0WrVnHzgwAEcHBwIDAy8z9HVmynm5i0NRVHYdyGJUYsPkJOnZ3ioLx8NaGq8APq14+pz1Kgd6vd2HtD9Awh+FrQ1auU9ALp+to2LibdX0tn6RhcauNmZMCIhxMOgUufmBXUR7pYtW3L16lWuXLkCQNu2bWt8Iq0JNBoN7Ru4MGdoCzQa+HFfNF9vO2dcyKMJjPwVnlkCtepD+jX4dRx8163GTU8Yn5bFxcRMNBoI8lJv5gNRSfc5Sgghqk6Zkqler+fDDz/E0dERPz8/fH19cXJy4qOPPkKv11d0jOIe+jbzYmp/tZPR55vOsOJgjHEBjQYC+8G4fdDr36BzgNhIWNwHYg5UfcBldOhWE2+gpwM9GqvjmPfLEBkhRDVSpg5I7733HgsXLuSTTz6hY8eOKIrC7t27mTp1KllZWXz88ccVHae4h1Ed6hKXmsX87ed555ejuNrr6BZw18QZ5jroMB6aPwPb/g2J56FOm9s/v7hLXepNVz17yBY8L21T15m29VyAc+yPSkJRFOOmbSGEMJEyJdP//e9//Pe//zWsFgMQHBxM7dq1GTdunCTTKvZW7wCupWTxS8QVxv14mKUvhRLs41S4oJ0b9J8D+Xl3TE2YAj89rU4AMTZcbRKuZg5eUpt0W9etRSs/J8y1GmJTsrh84yY+tWT6SiGE6ZWpmTcpKanIZ6OBgYEkJcmzrKqm0WiY8VRzOvu7cjM3n+fD/uJiQjHroJrd8RkqORocvMGxNjjXu73/4m64mVxpMZdURnYex6+mAmrN1MbSnGZ1HAF5biqEqD7KlEyDg4P56quvCu3/6quvaN68ebmDEqVnYaZl/vAQmtZ2IDEjh5GLDnA9Lfv+B3o2g1cPwog1t2uruTfh5yHwuT/8/Az8vdxkQ2siY5LJ1yvUdrLGy1Gd2L9tvVqAOkRGCCGqgzI183766ac89thjbNmyhfbt26PRaNizZw8xMTGsX7++omMUJWSnM2fR6DY8OX8P0UmZTFoeyffPt73/c0WNBhy8bn+fchkcfeD6STizQd3MrdQJ95sMhka9wdL23uerQH/dmqyhTd3bqxO1q1eLb3dckJqpEKLaKFPNtEuXLpw5c4ZBgwaRnJxMUlISgwcP5vjx4yxevLiiYxSl4G5vxeLRbdCZa9l5NoEf9pVhekdXf3hln9oL+JG3wKUh5GXByd9g5XMwoy58HgBzW6mr1yzqA8uGG5/j4CL4899w7cTtfSmX4cSvEHcM9PklCuXgrc5HIXVrGfa1rlsLjQYuJmZyLTWr9K9PCCEqWJknbSjKkSNHaNWqFfn5JftDWV1V90kbSiJsdxRTfzuBlYWWdRM6l2+CA0WBuKNw/Bc4vhpuXCxcxs4D3jxz+/uFvSFmHwz5AYJudVQ7uhJWjVG/1jlAndbgEwq+7aB2a9AZx5iXr6f5tE1k5uSzcWJnAj1v/y4em7uT41dTmftsS54I9i77axNCiGKUNB+UqZlXVH8j29dly8l4dp1LYNKySFa+3AELszLO0aHRgFdzdev+gZpMs1MhJxNyM9R/79ZkkFrepcHtfdZOUKctxJ9Qjz//p7qBOv2hR1N1yI6dO+jsics0p3VeIhFWITQqmNg+JwMsbWlbrxbHr6ZyICpRkqkQwuQkmT6gtFoNnz3dnN6zwjlyOYWvt51jYo9GJTo2OTMHnbkZ1pZFrJeq0UCteoX33y10bOF9DXuomz5fne4wZr+6Re+HlGiI+1vdbqkDTDKvzxy/HmgLJiSeFwrmVvRs/jGLkR69QojqQZLpA8zL0ZqPBjbltaWRfPnnOboFuBc9/vQWvV5h/o7zzNx0mla+zqwY275yJkXQmt2u6bZ9Ud2XehWi96nJNCsFslI5euEyh1KdaX3H81KyUiErmsb+/sAJzlxLJ2PnPGyjt4FPW/DrpDYfm1lUfNxCCHEPpUqmgwcPLvbnycnJpQ5g3rx5fPbZZ8TGxtKkSRNmz55tWHj8bqNHj+Z///tfof1BQUEcP34cgLCwMJ577rlCZW7evImVlVWp46vpngj2ZtOJa6z7O5bXl0eybnznImucyZk5TFp+hD9PxQNw8NINDkQl0a6+S9UE6uANTQerG+pk/s//ZyvX87JZfmcyHX8Yrkbg7FUPf/dozsank3FiE7ax2+DsJrWMhS3U7Qj1ukD9ruAeVCMn9xdC1BylSqaOjo73/fnIkSNLfL5ly5YxceJE5s2bR8eOHfn222/p27cvJ06cwNfXt1D5OXPm8Mknnxi+z8vLIzg4mKefftqonIODA6dPnzba9zAmUlAndPh4YFP+ikriwvUMZmw8xdQnjBcNPxKTzLifDnMl+SaW5loaedhx7EoqP+6PLnUyragp/qKTMrmelo2lmZbmde6472xdwL8HAO3q1+JsfDqrnUbzf8F9IHovXNwJmYlqYi1IrjauUL8L+HUAS3u1Zuzd8vbz3PTranOzlSPUK/qDnHhI6fPV+yk7Td1y0sGhdskedYiHSoX25i2tdu3a0apVK+bPn2/Y17hxYwYOHMj06dPve/yaNWsYPHgwUVFR+Pn5AWrNdOLEiWWqJRd4EHrz3m376XhGL/4LgB/GtKWzvxuKovD93kv8e90JcvMV/Fxs+PofrQB4/MtdWJhp2PNOd9zsdSW6hqIojP3xEEcvp/D7hM7UsrUsc7wrD13mzRVHCPFzZtXLHYoss/bIVSYsiaBpbQd+H38rCer1cO2YuvTche1waQ/kFtFB6vHZ0PpWC8b5bfDDQHDxh/EHb5dZ8g/ISgZ7T7D3UhdZd22kbvaetye5EA+GqHA4uFhdcemRN9V9yTEwu2nhst4toelTakuKg3SAe5BV+968OTk5HDp0iHfeecdof69evdizZ0+JzrFw4UJ69OhhSKQF0tPT8fPzIz8/nxYtWvDRRx8Vu2h5dnY22dm3ZwtKTU0txSupGboGuDM81Jcf90XzzxV/s2pcB6avP8nvf8cC0LuJB589HYyDlfqsMdjHiSMxySw/GMMr3RqW6Bp7zifyx/FrAGw+EcfQNoVbF0rq4MWC+Xid71mm3a2ZkE5cTSU1K1eNXau9/Ty2w3jIy4HLf6mJNTYS8nNB0Rv/AdQ5qL2M3QKMLxCzHzITir64pT24NlQTq4u/+rWjjzom19qpzK9bVCF9vjrsq2B6zUt71OFfVnf8wdTZARp1EQhLO7C0gaQouBqhbpv+BXU7QdMnIWgA2NQq8lLiwWeyZJqQkEB+fj4eHh5G+z08PIiLi7vv8bGxsWzYsIGff/7ZaH9gYCBhYWE0a9aM1NRU5syZQ8eOHTly5Aj+/v5Fnmv69OlMmzat7C+mhni3X2N2n0skKiGDbp9tJydfj7lWwzt9AxnTqZ5R8+zwdr4ciUnm5/3RjO3SADNt8bUwRVGYs+Ws4fsdZ66XK5kaZj7yu/cfJw8HK+q62HAxMZNDF2/QLdC9cCFzS/X5ad2O975YnRB4YXPh/UN/hLSrkBqrdpBKugAJZ9ShQTlpt/+g3umJr6DVCPXrK4dh92zwbgWdJhb7ekUpZCSqzfm5N6HFs7f37/hU7cSWlawOtbJxVR8L2Ljc+tpV/dpcB2f+gGOroN/nt8dBN3tabcpt8Y/b57RygilJxs/c06/DiTXquOmYfWosF3fC+jehQXf1OX37cZX/PohqxeS9ee9+vlbSZ25hYWE4OTkxcOBAo/2hoaGEhoYavu/YsSOtWrXiyy+/ZO7cuUWea/LkyUyaNMnwfWpqKj4+PqV4FTWDjaU5M4cE89T8PeTk6/F0sOLrYS0JKSJh9Q/25t/rTnIl+SY7zsTzaKBHEWe8bd+FJA5cvD1MZefZBPLy9ZiXYWxrYno256+rE/WH+N27ZgrqPL0XEzPZH5VUdDItD7/2Re/Py4EbUWpiTTgDCecg8ZyacB3r3C53/ZQ641N2mnEyXTZCrcXWaa2Oq3WsI03GxVEU9VllwRKBaVdhxSjQmkPwM7ffu9gjcH5r6c596vfbydSlAfS+a8Urjabw78bOTe2F3vZFdaGIY7+oifXaUTj7B2RcN06mi/qq//affbv1Iz9XjV9+7w8MkyVTV1dXzMzMCtVC4+PjC9VW76YoCosWLWLEiBFYWhb/XE6r1dKmTRvOnj17zzI6nQ6drmTPBWu6Vr7OzHmmJYejb/Bqt4a42BX9uq0szHgqpA4Ld0Xx477o+ybTuVvV93dYO1/WH43lRmYuh6OTDZPSl8ahS+oUgv7udjjf57lr23ouLD94mQNVOem9uaX6R/HuZuG71W4NfT9VJ6EokH4dTq41LmfnAZ7NwT1Q7XnsFqieu4rmP66W8nLU2t7pDerm1wGe/E79mUdTaHQrQeXnqr8PgDZjIPBxtSOZkg8ZCWrnoczEO75OUIde1W6t1kQbPFq+OJ181Q9KnSbC9dNwer16/QL5eXD5AOjzwOKO5QLDP4O/FoJnU/X1eDZT/3ULkGFdNZTJkqmlpSUhISFs3ryZQYMGGfZv3ryZAQMGFHvsjh07OHfuHGPGjLnvdRRFITIykmbNmpU75gdF/2Bv+pdg1qBh7XxZuCuKbafjiUnKvOfaoQeikth7IRELMw2vdGtIenYev0ZeZfvp+DIl04O3kqnR+NJ7KHhu+vflFDJz8rCxNHljy21ujdTtThZWMOhbuHxQfZZ77RikX4Nzm9XNQAPOfmpy9WgCrUaB04PXWmKQexOuHIJLe9Ve2TEH1Kb0Apd2qzXUgpriP5YWPkd5E2N5FfUBS6OBMZsh8bzaC7jAteNqYr+wXd0KmFtD7RB1zLRPO/Xf0jyHzUpRz2Fe9s5/omxM+pdn0qRJjBgxgtatW9O+fXsWLFhAdHQ0Y8eqs+dMnjyZK1eu8P333xsdt3DhQtq1a0fTpoV72U2bNo3Q0FD8/f1JTU1l7ty5REZG8vXXX1fJa3qQ1Hezo2NDF3afS2TJgWje6lN4DVu4XSt9urUP3k7WdA1wu5VMr9/zmOIUtVLMvdRxtsbb0YqrKVlERCfTsaFrqa9XpXT2atNk8DPq97k3IfZviD8O8afUqRavn1KbCm9cVLfT66H5M7fPkZ2mdoapyU2EN2+ozzcv7VH/vRoB+lzjMrbuENAXAvqpQ5tq4uvVmkHtVup2p8HfQfxJ9cPUtWPq4g/XjqnTbF7apW4FXBupSTVokGFYGFcOwcZ31efAz/x0u2zY4+rEJ+bWag3ZykH9V+egdrpzCwDXAPVDnqOvjL+uQCZNpkOHDiUxMZEPP/yQ2NhYmjZtyvr16w29c2NjY4mOjjY6JiUlhVWrVjFnzpwiz5mcnMxLL71EXFwcjo6OtGzZkvDwcNq2bVvpr+dBNLydH7vPJbL8YAwTezTC0tz4P9+hS0nsOpeAuVbDy13UcZuP+Luh0cCJ2FTiU7Nwdyj5GN+bOfkcu5ICQJsS1Ew1Gg1t69ViTeRV9kclVf9kejcLa3Wif992xvszEtQ/tvEnIfWy2lu4wJqX1dV4+n0GDbur+7JSIS1OreVmxEP6rS0zQf2jWSdE7QhVHXoan90MPw9Vm2LvZOepPqf27QC+oWqz54P6x97SRv2d1Am5vU+vh8Szt6fZjDlwx3P5M2DvfTuZgtr5yf6uFqYs9f8OeTch/SakF9OZ09xK7YneYTwED1X3ZSapH2zsPNQm6Oru5g211m+uU5vKCxxfrf6faDLQuNm9Epm8TWzcuHGMG1d0z7ewsLBC+xwdHcnMLGLc4C2zZs1i1qxZFRXeQ69HkAfu9jri07LZeDyu0KTyc7aeA+DJVnUMzcAudjqa1Xbk78sp7Dhznadbl7x58sjlZHLzFTwcdNRxti7RMe3qu6jJ9MIDtFi4ras6gcTdk0jk5cDFXeofEVu32/vX/xP+LqLp826ujdTnhXVCwK8juDeu2Ljvdv0MHF2hLuvXfIi6z7sVoKjDiPw63E6eznVrZu2zomi1t5uKW92a/CYzSX0cEL1PXUe4gIs/PB0GDnWMzzEhQq3dZqUYpuU0fJ18SX2um3BW7TCXl6V2msq7YxnD2CPw42D18cK4vbf3f/copFxRPwRY3NoKfW17e5+lLfi2B+8W6vH5uWoMNi73/x1nJqkJMvEcJJ2HtFi1B3dmgvohs/d/ILCfWvbiblg2TB3admeP/I2T1eN8Qx+eZCqqNwszLc+09WXu1rP8uO+SUTKNiL5B+JnrmGk1hcaidm3kxt+XU9heymR6e3xprRLPpFTwXDYiJpnsvHx05kVM0P+gMLeEicfgwjbjT+J27qBzVP8t2GzdwdpZ/aN05aDaZFxQyznyszrpwFML1ePz82D/fDW51u+mNk+WRl62ep3rp8Crxe3ZpS5sg/BP1YRZkExtXeD1E8YL0oui2dRSk+idiRTU5tsmgwqX15qpv3Pr+zwi0effuh/OGtdAtebg3sS4JQTUySsy4ksXe8+PbifT+JPwbWe1F/vrx26XifhJ7Z2deEG9fxLPwc37LF6RdvX211YOaiewOzv5gTo86WayWvuuIpJMxX0929aHr7ed40BUEmeupdHIQx2i8OWfaq10UMva+LoYd07qEuDO3D/PsfPM9VINkfnr1mLgbe4zJOZO9V1tcbXTkZCezd+XU0rUPFyj6eygcX/jfT2mQa+Pij8uI0Ht+HTloPpvvUdu/yzpvDoBgYUtTL58e//WD9VxtlqzW5v5rSEdt5Jt8iU1gSZdUCfDALUHc0EyDein9spt/IRxLJJITUtrpv6O7lwiEdSWkHFFTJrz/EZ1+cPczFv/3rzj68zbX9+5LKPbHf0l0m8lYpu7pifdOVO99+7mUFuNrVYDcKx9a5ywm9pi43LHfAH1HoGJRwsfP+ibkr0PFUiSqbgvL0druge6s+nENX7eH83UJ5pw9HIKf56KR6uhyBmSWvg44WRjQXJmLpExySXqmZuvVzhcip68BTQaDe3q1WLd0VgORCU9+Mm0KCV5tmjrCgF91O1uigJBA28lzDvOdXqD2imqJHSO6vAeK6fb+5x81MkvRM12d9ItLf8e8K94tdnZaH8vtfm3Vn21NuzSUP26Bg4Lk2QqSmR4qB+bTlxj1aHLvNUngDm3evAOaFGbeq6Fb3wzrYbO/m78dkTt1VuS5HgqLpW07DzsdOYEetqXKr62t5LpnvMJJZ7+UNzBPRCGFF6Rifavqj2LlXy1aVCfd2vLV/c5+tx6zheodlp5mJ95iuKZ69QJL+7U95Oiy9ZAkkxFiXRq6Iqfiw2XEjP5ZMMptpy8huYetdICXRrdSqZn4nmz930mOAD+urXQd0tfp1LPnNSlkdqDePe5RI5dSaFp7arpdPDAaznM1BEIUSM8oP3ORUXTajUMa6fOtfv93ksA9G/uTUN3u3se06WR+in02JVUrqdl37McQG6+nh/2qeft0KD0w1vqutoy4FbnqFmbz5T6eCGEKA9JpqLEng7xMYwz1Wjg1UeLb051s9fRtLa6Akf4mevFll1yIJrz1zNwsbVkWGjZJsh/rUcjzLQatp6K53D0jTKdQwghykKSqSgxZ1tLHm+u9sLs19TL0Ku3OF0bqV3WtxeTTFNu5hpqkxN7NjIsA1da9VxteaqVOu7ui01SOxVCVB1JpqJUpjwexDt9A/l4UMlmR+kaoDb17jx7nXx90evQz9t2jhuZuTR0t+PZNuWbf3Z894ZYmGnYdS6BvecfoEkchBDVmiRTUSpONpaM7dIAJ5uSTaTdwscJBytzwxCZu0UnZrJ490UA3uvXuExLtt2pjrMNz7ZVm4m/2HwaRSk6gQshREWSZCoqlbmZls7+au10x+nCM6jM2HiKnHw9nf1dDbXY8nqlW0N05lr+uniD8LMJFXJOIYQojiRTUem63EqSO+56bnroUhLrjsai1cB7jzUu8fSB9+PhYMWIUHWxhJmbpHYqhKh8kkxFpet6a4jM31dSSExXh8jo9Qof/n4SgCGtfQj0dKjQa47t2gAbSzP+vpzC5hPXKvTcQghxN0mmotK5O1gR5OWAokD4WbV2+tvfVzkSk4yNpRmTejW6zxlKz9VOx3Md6wLwxeYz6O/R+UkIISqCJFNRJQqaerefvk5Wbj6fbjwNwMtdGuBuXzkrO7zUuQH2Vuaciktj3dHYSrmGEEKAJFNRRQqaesPPXOe/Oy9wJfkmXo5WvNC5fqVd09HGghdvnX/WljPk5esr7VpCiIebJFNRJVr5OWOvM+dGZi6ztqiT5L/VJwBry8pde/S5jnVxtrHgwvUM1kRevf8BQghRBpJMRZWwMNPSyV+dczdfr9C8jiMDgmtX+nXtrSwY20VdPmrO1jPk5EntVAhR8SSZiipTMPE9qBM0aLVVs1zXyPZ1cbXTEZN0k3dXHyUrN79Cz3/8agrf771IRnZehZ5XCFFzSDIVVaZvUy+a13Hk+Y71aFffpcqua21pxnuPBaLRwMpDlxn49W7OxaeX65yKorD/QiKjFh3gsbm7mPLrcd5a9beMaRXiIaVR5H9/IampqTg6OpKSkoKDQ8WOfxSms+tsAhOXRZCQnoONpRkfD2rKoJZ1SnUOvV7hz1PxzN9xnkOX1JVptBrQaDTk6xXmPNOCAS0qv/laCFE1SpoPpGYqHhqd/F1ZP6Ez7eu7kJmTz+vLjvD2yr+5mXP/Zt+8fD1rIq7Qd85OXvj+IIcu3cDSTMs/2vmy7c2uTHjUH4D31xwjNuVmZb+UcsvKzedAVBLrj8ZKL2chKoDUTIsgNdMHW75eYe7Ws8z98yyKAgEe9nw9rCUN3W8vKXc9LZvjV1M4fjWVY1dSOBx9g2up6uxNdjpzhoX6MqZjPdwd1DGyufl6npq/hyOXU+js78r3z7ct0fSIyZk5fL3tHN0C3OnQsPSLopfU1eSbHI6+waFLNzh86QbHr6aSd2siixGhfnw0sGSrAAnxsClpPpBkWgRJpg+HPecSmLA0koT0bKwtzHimrQ8xSZkcu5JKXGpWofIutpY836kew0P9cLQuvObq+evp9Juzk+w8PR8OaMLI9nWLvf71tGxGLNzPqbg0vByt2PX2o5hVYKesmKRMvth8hn0XEolNKfx6XO10JNya3nHm08E8GVK6Jm8hHgY1ppl33rx51KtXDysrK0JCQti5c+c9y27fvh2NRlNoO3XqlFG5VatWERQUhE6nIygoiNWrV1f2yxA1UIeGrqx/rRMdG7pwMzefxbsvsuVkPHGpWWg00MDNlgEtvHmvX2N+fqEdu995lFe6NSwykQI0cLNjct9AAP6z/iQXrt+7k9PV5JsM/XYvp+LSAIhNyTJMtVgR1kRcod+cnayOuEJsShZmWg3Najsyqr0fc55pwc63uvHXe92Z0F1tnn539VGOX02psOsL8bAxN+XFly1bxsSJE5k3bx4dO3bk22+/pW/fvpw4cQJfX997Hnf69GmjTwhubreHXOzdu5ehQ4fy0UcfMWjQIFavXs2QIUPYtWsX7dq1q9TXI2oed3srvn++HT/tv8SJq6kEetrTtLYjjb0csNWV/r/HyPZ12XIynl3nEpi0/Agrx7YvtEbrpcQM/vHdfq4k36S2kzXN6ziy4Vgcyw7E0C3AvVyvJ+VmLu+vOcbaI+oEFSF+zrzRqxEtfJywsSz8eiZ29+fvy8lsP32dsT8e4vdXO+NoU/SHBSHEvZm0mbddu3a0atWK+fPnG/Y1btyYgQMHMn369ELlt2/fTrdu3bhx4wZOTk5FnnPo0KGkpqayYcMGw74+ffrg7OzMkiVLShSXNPOK8riafJPes8NJy8rjjZ6NGH+r9gdw5loaw/+7n/i0bOq52vLTC+1Iy8qj9+xwzLUa9k7ujpu9rkzX3XchkTeWH+FK8k3MtBpe6+7PuK4N7rvgenJmDo9/uYvLN27SLcCNhaPaVNkYYCGqu2rfzJuTk8OhQ4fo1auX0f5evXqxZ8+eYo9t2bIlXl5edO/enW3bthn9bO/evYXO2bt372LPmZ2dTWpqqtEmRFl5O1nz0QC1Q8+crWc5dkVtPj16OYWh3+4lPi2bQE97lv1fKN5O1gR42tPCx4k8vcIvhy+X+no5eXpmbDzFs9/t40ryTfxcbFg5tj0TuvvfN5ECONlY8s3wEHTmWradvs6Xf54rdQxCPOxMlkwTEhLIz8/Hw8PDaL+HhwdxcXFFHuPl5cWCBQtYtWoVv/zyCwEBAXTv3p3w8HBDmbi4uFKdE2D69Ok4OjoaNh8fn3K8MiFgQAtv+jXzJE+v8PqySHadTeAf3+3jRmYuwT5OLH0p1Gi1nGfaqPfcsoMxpZr44fz1dAbP38387edRFBja2of1EzrT0te5VPE2re3Ix4OaATB76xm2nY4v1fFCPOxM3gHp7uEDiqLcc0hBQEAAL774Iq1ataJ9+/bMmzePxx57jM8//7zM5wSYPHkyKSkphi0mJqaMr0YIlUaj4d8Dm+Fmr+NsfDrDF+4nLTuPdvVq8dML7XCysTQq/3iwNzaWZly4nsHBW5NB3E9yZg5DvtnLsSupONlY8M3wVsx4qnmZnvUCPBVSh2HtfFEUmLg0kpikzDKdR4iHkcmSqaurK2ZmZoVqjPHx8YVqlsUJDQ3l7Nmzhu89PT1LfU6dToeDg4PRJkR51bK1ZMaTzQzfdw1wI+y5ttgVkezsdOY83twLgKUHSvZhbvaWsyRm5NDQ3Y4/Jj5Cn6Ze5Y55Sv8ggn2cSLmZy//9cKjC5zEW4kFlsmRqaWlJSEgImzdvNtq/efNmOnToUOLzRERE4OV1+49I+/btC51z06ZNpTqnEBXl0UAPZjzZjNd7NGLBiNbFLjk3tI3ag3390VhSs3KLPe/Za2n8sO8SANOeaIKHQ8UssK4zN2P+sFa42FpyIjaVf605ViHnFeJBZ9KhMZMmTWLEiBG0bt2a9u3bs2DBAqKjoxk7diygNr9euXKF77//HoDZs2dTt25dmjRpQk5ODj/++COrVq1i1apVhnO+9tprPPLII8yYMYMBAwbw66+/smXLFnbt2mWS1yhEQZK8n1a+Tvi723E2Pp3fjlxlWDu/IsspisKHv58gX6/Qu4kHHSt45iRvJ2u+fLYlwxfuZ+Why/Rr5smjgSVvLRLiYWTSZ6ZDhw5l9uzZfPjhh7Ro0YLw8HDWr1+Pn5/6RyQ2Npbo6GhD+ZycHN58802aN29O586d2bVrF+vWrWPw4MGGMh06dGDp0qUsXryY5s2bExYWxrJly2SMqaj2NBoNQws6Iv1176berSfj2Xk2AUszLe/1C6qUWDo0dOWFzvUB+GDtcWnuFeI+ZDrBIsg4U2EqienZhE7fSm6+wvoJnQnyNr7/svPy6T0rnIuJmbzctQFv9wmstFgysvPo8cUOYlOymPBoQyb1Cqi0awlRXVX7caZCiMJc7HT0CvIEYPnBwrXT/+25yMXETNzsdbzSrWGlxmKrM+eD/mrN95sdF4qdHlGIh50kUyGqmSG3mnp/OXzZqHn1elo2c7eqEyq81TugyF7BFa13E0+6BriRk69nyq/HZfFzIe5BkqkQ1Uynhq7UdrImNSuPP47fHub1+R+nSc/Oo3kdR55sVTUrvGg0GqY90QRLcy27ziXw+9+xVXJdIWoaSaZCVDNmWg1Pt1aTZUFHpGNXUlh+SP36g/5NqnTuXD8XW17pqjYpf/T7CdLuM2xHiIeRJFMhqqGnW/ug0cCe84lcTMhg2m/HURR1msIQv9JNFVgR/q9Lfeq62BCfls0Xm89U+fWFqO4kmQpRDdV2sqazv7q04KtLDvPXxRtYW5jxTt/K671bHCsLMz68NXn///ZclLVPhbiLJFMhqqmCye+PXVFXMXq5awO8HK1NFs8jjdx4rLkXegX+teYYer10RhKigCRTIaqpHo09qGWrTohf28malx6pb+KI4P3HgrC1NCMiOrnIoTsPuj3nE4iILtlCBOLhIslUiGrK0lzLS4/Ux8JM7VFrZXHveX2riqejFa/3bATAJxtPkZSRY+KIqs7RyykM++9+nlmwj2upWaYOR1QzMgNSEWQGJFGd5OXrS7TId1XJy9fz+Je7OBWXhpejFd0C3enSyI0ODVywt7IwdXiVQlEUhv13P3vOJwLwQqd6/OvxypnKUVQvJc0HkkyLIMlUiOIdiUlmxML9pGblGfaZazWE+DnTJcCNLo3cCPJyKHYd4Zpkx5nrjFp0AI0GFAWsLczY/c6jhmZ48eCSZFoOkkyFuL/MnDz2X0hix5nr7DhznaiEDKOfezjoGNbOjxGhfjjX4KSj1ys89uUuTsam8kKneuyLSuTYlVTGP9qQN2S+4geeJNNykGQqROldSswg/FZi3XM+kcwcdSpEawszhrbxYUynevjUsjFxlKX3y+HLTFp+BHsrc8L/2Y39UYmM/fEw9lbm7H7nURwe0KZtoZJkWg6STIUon+y8fDYei+PbHRc4EasO7dFq4LHm3vzfI/VpWtvRxBGWTFZuPt1n7uBK8k3e6hPAuK4N0esVes8O52x8Ov/sHVDpCw4I05JVY4QQJqMzN2NAi9qsm9CJH8e0o7O/K3oFfjtylce/3MU/vtvHgagkU4d5Xz/uu8SV5Jt4OljxfMd6AGi1GsZ1awDAwl1RZObkFXcK8ZCQZCqEqDQajYZO/q78MKYd6yZ0YmALb8y0GvacT+Qf3+1j/4VEU4d4Tyk3c/lqm7pKz6SejYyGJvVv7o1vLRuSMnJYcsD0421z8/XczJEF3E1JkqkQoko08XZk9jMtCX+rGz0ae5CnV3jl58PEptw0dWhFmr/9PMmZufi72zG4VW2jn5mbaXm5q1o7XRB+nuy8qk1kN3Py2XMugVmbz/CP7/bRfOomWn60idNxaVUah7hNkqkQokrVdrLmy2db0tjLgYT0HMb+eNho3dbqIDblJot3RwHwdp/AIsf5Dm5VG08HK66lZrPy0OVKjUdRFHacuc709ScZNG83zab+wT/+u585W8+y53wiN3PzycrVs2hXVKXGIe5NkqkQospZW5qxYEQITjYWHIlJZsqvx6rVwuOzNp8hO09P27q16N7YvcgyOnMzwxSP3+w4T16+vtLi+WTDKUYtOsC34ReIiE4mT6/g5WjFgBbe/HtgU2YNDQbg1yNXSMmUJfJMQZKpEMIkfGrZ8OWzLdFqYPnBy/y4P9rUIQFw5lqaoab5dt/AYieeeLatLy62lsQk3WTtkauVEs+6v2P5NvwCAE+2qsMXQ4LZ+VY39rzzKHOeacnwUD8GtqhNoKc9Wbl6Vhwy/TPch5EkUyGEyXT2d+PtPuqyctPWHuevi6bv4fvpxlPoFejTxPO+a8daW5oxprPay/frbecqfCWds9fS+OfKIwD83yP1mTkkmMGt6uBTy8YoyWs0Gka2rwvAT/ujZUUfE5BkKoQwqZceqc9jzb3I0yu8/ONh4lKKn0T+elo2x66kVErCOBCVxJaT8ZhpNfyzT8lmNxoR6oeDlTnnr2ew8XhchcWSlpXL//14iMycfNrXd+GfvYuPZ0ALb+x15kQlZLD7fEKFxSFKRpKpEMKkNBoNnz3VnEBPexLSs3n5p0OFescWdAga8u1e2v5nC49/uYvHv9zF1pPXKuxZa26+nmm/HQfUtWQbuNmV6Dh7KwtGd7xdO62IeBRF4Z8r/ubC9Qy8HK348h8t77vYga3OnCdD6gDw/d5L5Y6hKlxNvsm5+AejB7IkUyGEydlYmvPtiBAcrS2IiE5m6toTxCRlsiD8PIPm7ab99D+Z9tsJDkQloSigM9dyIjaVMf87yKB5e9h1NqHcSeyb7ec5fjUVR2sLJvZoVKpjn+tQFxtLM45fTWX76evligPgmx0X2Hg8DkszLfOGtcLVTlei44aH+gGw9eQ1riRXzyFHufl6NhyNZeSiA3Sc8Se9ZoVz6JLpm/fLy+TJdN68edSrVw8rKytCQkLYuXPnPcv+8ssv9OzZEzc3NxwcHGjfvj1//PGHUZmwsDA0Gk2hLStL1h8Uojrzc7Fl7rMt0WhgyYFoOn+6jf+sP0VEdDIaDbSp68z7jwex+51H2Te5O2O7NMDKQktkTDLDF6rrjJb1mevpuDTm/nkWgGlPNMHNvmTJq4CzraUhkX32x2nyy9EEvftcAp/9cQqAD54IoqVv8c9t79TQ3Y4ODVzQK/Dz/upVO41KyGD6hpO0n76Vl386TPiZ6ygK6BWYveWsqcMrN5Mm02XLljFx4kTee+89IiIi6Ny5M3379iU6uuhefeHh4fTs2ZP169dz6NAhunXrRv/+/YmIiDAq5+DgQGxsrNFmZWVVFS9JCFEOXRq58VZvtUOSVgMdGrjw0YAm7J/cnRVjOzCmUz1qO1njbGvJO30DCX+rG891rIulmZb9UUk8/c1eRi06wLErKSW+Zl6+njdXHCE3X6FHYw8GtPAuU+xjuzTA3sqcE7GprCrjuNMryTcZvyQCvQJPh9ThH219S32OEbeS+rK/Yqp8Mom75eTp+TXyCs8s2Eu3z7fz7Y4LJKTn4Gqn4+WuDfjphXaYaTXsPJtAZEyySWMtL5NOdN+uXTtatWrF/PnzDfsaN27MwIEDmT59eonO0aRJE4YOHcqUKVMAtWY6ceJEkpOTyxyXTHQvhGkdvZyCt5MVLiVs3ryafJOvtp1j+V8x5OkVLM21fDsihG4BRY8RvdPX287x2R+ncbAyZ8ukLrg7lP2D9393XuDf607iaqdj+z+7YqczL/GxWbn5DP12L0cup9C0tgMrx3YwmsKwpPLy9XSc8SfXUrOZ80wLBrSoff+DKlhmTh5LD8Tw3c4LxN7qUKbRqB+WnmnjS/fG7ljcegb8xvIjrDp8me6B7iwc3abKY72faj/RfU5ODocOHaJXr15G+3v16sWePXtKdA69Xk9aWhq1atUy2p+eno6fnx916tTh8ccfL1RzvVt2djapqalGmxDCdJrVcSxxIgXwdrLmP4Oa8ecbXekW4EZOnp7/+/4QW09eK/a4M9fSmHOriXHqE03KlUgBRravSz1XWxLSs5l3a17fkpr22wmOXE7BycaC+cNCypRIQZ3q8B9t1drpD1XcESklM5cvt56l04xtfPj7CWJTsnCz1/Fad392vf0oYc+1pU9TT0MiBXilWwO0Gth6Kr5ULQrVjcmSaUJCAvn5+Xh4eBjt9/DwIC6uZN3LZ86cSUZGBkOGDDHsCwwMJCwsjLVr17JkyRKsrKzo2LEjZ8/eu01++vTpODo6GjYfH5+yvSghhEn5utiwYGRr+jXzJCdfz9gfD7HpHsNV8vL1/HPFEXLy9XQPdGdQy/LX4CzNtbzXrzEA/90VRUxSZomO+2n/JZYciEajgbnPtCz3uq/PtvXBXKvh4KUbnLha+ZWD+LQspm84SccZfzJz8xmSMnLwrWXDx4OasvOtbrzesxG1nayLPLa+mx39g9Wm9S//rLnPTk3eAenu2UUURSl2xpECS5YsYerUqSxbtgx399tNOaGhoQwfPpzg4GA6d+7M8uXLadSoEV9++eU9zzV58mRSUlIMW0yMzCAiRE1lYaZl7jMteby5F7n5CuN+OszGY7GFyn23M4ojl1NwsDLnP4OblejvTkl0b+xOp4au5OTp+WTDqfuW338hkQ9+VYfkvNkrgEcauZU7BncHK3o39QTgx0rsiJSvV/jo9xN0mrGNb3dcID07j0BPe+Y804I/3+jCsHZ+Japhv9qtIRoN/HH8GqfiambLoMmSqaurK2ZmZoVqofHx8YVqq3dbtmwZY8aMYfny5fTo0aPYslqtljZt2hRbM9XpdDg4OBhtQoiay9xMy+yhLRjQwvvW6jQRrPv7dkI9ey2NWZvPADClfxM8ytm8eyeNRsO/Hm+MVgPrjsYWu27r5RuZvPzTYfL0Cv2DvRl3ayWailDQEWlNxBVSsypnvt5vdpxn4a4ocvL0hPg5s3BUaza81pkBLWrfd1zsnfw97OnX1AuAL/8sXfN4dWGyZGppaUlISAibN2822r9582Y6dOhwz+OWLFnC6NGj+fnnn3nsscfuex1FUYiMjMTLy6vcMQshag5zMy1fDGnB4Ja1ydcrTFgawdojV9Xeuyv/JidfT7cAN55sVfEddAI9HXj2Vk/cD38/XuRsTZk5ebz4/SGSMnJoWtuBT59sXmG1Y4B29WrRyMOOzJx8fqmEVW2OX01h9hb1A8nHg5qycmx7ujf2KPNrePXRhgCsPxpbIydyMGkz76RJk/jvf//LokWLOHnyJK+//jrR0dGMHTsWUJtfR44caSi/ZMkSRo4cycyZMwkNDSUuLo64uDhSUm4/tJ42bRp//PEHFy5cIDIykjFjxhAZGWk4pxDi4WGm1fDZ08E8FVKHfL3CxKURjP3xMEdikrG3Mmf64IpNYHea1LMR9jpzjl1JZdVh42RWMMPRydhUXO0sWTCiNdaWZetwdC8ajcZQO/1h36UKXZUnKzef15dFkpuv0LuJB/9o61vu97GxlwO9gjxQFPh62/kKirTqmDSZDh06lNmzZ/Phhx/SokULwsPDWb9+PX5+6g0QGxtrNOb022+/JS8vj1deeQUvLy/D9tprrxnKJCcn89JLL9G4cWN69erFlStXCA8Pp23btlX++oQQpmem1fDpk815po0PegW23Orh+/5jQXg6Vt74cxc7HRO6+wPw6R+nycjOM/zs623nWHc0FgszDfOHh+B9j8455TWwZW1sLc04fz2DvecTDfvz9QoJ6dmcuZbGnvMJ7DhzvVRryn6x+QxnrqXjaqfjP4Mq7nnz+EfV9+vXyCtEJWRUyDmriknHmVZXMs5UiAePXq/wr1+P8fP+aB4NdGfhqNaVVistkJOnp9esHVxMzOTVbg15s3cAm09c48XvDwIwfXAzQ3NwZfnXmqP8uC8aTwcr7K3MScrIISkzh7v/8jfxdmDx6Db3HR6070Iiz363D0WB/45sTY+g4vu4lNbzYX/x56l4ng6pw2dPB1foucui2o8zFUKIqqTVavh4YFM2vf4IC0aEVHoiBXWozLu3hsos2HmBbafimbhUHfc+sr1fpSdS9Tp10WogLjWLs/HpJGbcTqTONhY0cLPFwcqc41dTGTRvT7HPK9Oycnlj+REUBYa29qnwRAow/taz09URV0o8tKg6kJppEaRmKoSoKIqiMOy/+9lzRzNr+/oufD+mrdHkBZXp4MUkriTfxNVOh4udJbVsLallY2nocXspMYPRi/8iKiEDR2sL/juqNW3q1ip0nn+uOMKKQ5fxqWXNhtceKdUMT6UxYuF+dp5N4Nm2vkwf3KxSrlFSUjMVQohqQKPR8P7jQWhvVYTrOFvz9bBWVZZIAVrXrcWAFrXp2NCVQE8H3O2tjIau+LnYsurlDrT0dSLlZi7D/rufDUeNx+ZuOh7HikOX0Whg5tMtKi2RAoZnzSsPxXC1mq5+czdJpkIIUckaezkw/lF/6rvZ8t3I1tSytTR1SIXUsrXk5xdC6RnkQU6ennE/H2bRrigAEtKzmfzLUUBdzL1tvcK11orUpm4tQuvXIjdf4d3VR9l+Ot6oA1d1JM28RZBmXiHEwypfrzB17XF+2KfOnPRCp3pcSspk84lrBHra8+urHdGZV+wwnqLsPa92dCpgrtXQvI4j7Ru40L6+KyF+zhU+nKgoJc0HkkyLIMlUCPEwUxSFb3ZcYMbG29MhWphp+PWVTgR5V93fxB1nrvPbkavsPZ9YaLFzCzMNLX2ceay5FwNaeONkUzm1fUmm5SDJVAgh1KkI/7lSXev17T6BvFyB0x2WVkxSJnsvJLLvfCJ7LyQalnYDsDTT0jPIg6da1+ERfzfMtBXXU1uSaTlIMhVCCNWxKymcjU/jieDaFZqkykNRFKKTMtl6Mp6Vhy5zIvb25PgeDjoGt6rD0yF1qO9mV+5rSTItB0mmQghRcxy7ksLKQ5dZE3mF5Mzbk/qH+Dnz3mONaeXrXOZzlzQfVF7fZiGEEKIKNK3tSNPajkzuF8jWk/GsOBjDjjPXOXTpBraWVZPmJJkKIYR4IOjMzejXzIt+zby4lprF9tPxBHjaV8m1ZZypEEKIB46HgxVD21T+dI0FJJkKIYQQ5STJVAghhCgnSaZCCCFEOUkyFUIIIcpJkqkQQghRTpJMhRBCiHKSZCqEEEKUk0zaUISCGRZTU1PvU1IIIcSDrCAP3G/mXUmmRUhLSwPAx8fHxJEIIYSoDtLS0nB0dLznz2Wi+yLo9XquXr2Kvb09Gk3ZV0lITU3Fx8eHmJiYGjFhvsRbuSTeyiXxVq6HNV5FUUhLS8Pb2xut9t5PRqVmWgStVkudOnUq7HwODg414uYrIPFWLom3ckm8lethjLe4GmkB6YAkhBBClJMkUyGEEKKcJJlWIp1OxwcffIBOpzN1KCUi8VYuibdySbyVS+ItnnRAEkIIIcpJaqZCCCFEOUkyFUIIIcpJkqkQQghRTpJMhRBCiHKSZFoK8+bNo169elhZWRESEsLOnTuLLb9jxw5CQkKwsrKifv36fPPNN4XKrFq1iqCgIHQ6HUFBQaxevdok8f7yyy/07NkTNzc3HBwcaN++PX/88YdRmbCwMDQaTaEtKyuryuPdvn17kbGcOnXKqFx1eX9Hjx5dZLxNmjQxlKnM9zc8PJz+/fvj7e2NRqNhzZo19z3GlPdvaeM19f1b2nhNff+WNl5T37/Tp0+nTZs22Nvb4+7uzsCBAzl9+vR9j6vKe1iSaQktW7aMiRMn8t577xEREUHnzp3p27cv0dHRRZaPioqiX79+dO7cmYiICN59910mTJjAqlWrDGX27t3L0KFDGTFiBEeOHGHEiBEMGTKE/fv3V3m84eHh9OzZk/Xr13Po0CG6detG//79iYiIMCrn4OBAbGys0WZlZVXl8RY4ffq0USz+/v6Gn1Wn93fOnDlGccbExFCrVi2efvppo3KV9f5mZGQQHBzMV199VaLypr5/Sxuvqe/f0sZbwFT3b2njNfX9u2PHDl555RX27dvH5s2bycvLo1evXmRkZNzzmCq/hxVRIm3btlXGjh1rtC8wMFB55513iiz/1ltvKYGBgUb7/u///k8JDQ01fD9kyBClT58+RmV69+6tPPPMM1Ueb1GCgoKUadOmGb5fvHix4ujoWO7YilLaeLdt26YAyo0bN+55zur8/q5evVrRaDTKxYsXDfsq8/29E6CsXr262DKmvn/vVJJ4i1KV9++dShKvqe/fO5Xl/TXl/asoihIfH68Ayo4dO+5ZpqrvYamZlkBOTg6HDh2iV69eRvt79erFnj17ijxm7969hcr37t2bgwcPkpubW2yZe52zMuO9m16vJy0tjVq1ahntT09Px8/Pjzp16vD4448X+uRf1fG2bNkSLy8vunfvzrZt24x+Vp3f34ULF9KjRw/8/PyM9lfG+1sWprx/K0JV3r/lYYr7tyKY+v5NSUkBKPT7vVNV38OSTEsgISGB/Px8PDw8jPZ7eHgQFxdX5DFxcXFFls/LyyMhIaHYMvc6Z2XGe7eZM2eSkZHBkCFDDPsCAwMJCwtj7dq1LFmyBCsrKzp27MjZs2erPF4vLy8WLFjAqlWr+OWXXwgICKB79+6Eh4cbylTX9zc2NpYNGzbwwgsvGO2vrPe3LEx5/1aEqrx/y8KU9295mfr+VRSFSZMm0alTJ5o2bXrPclV9D8uqMaVw93JsiqIUu0RbUeXv3l/ac5ZGWc+9ZMkSpk6dyq+//oq7u7thf2hoKKGhoYbvO3bsSKtWrfjyyy+ZO3dulcYbEBBAQECA4fv27dsTExPD559/ziOPPFKmc1ZmvHcKCwvDycmJgQMHGu2v7Pe3tEx9/5aVqe7f0qgO929Zmfr+ffXVV/n777/ZtWvXfctW5T0sNdMScHV1xczMrNCnlfj4+EKfagp4enoWWd7c3BwXF5diy9zrnJUZb4Fly5YxZswYli9fTo8ePYotq9VqadOmTbk/eZYn3juFhoYaxVId319FUVi0aBEjRozA0tKy2LIV9f6WhSnv3/Iwxf1bUarq/i0PU9+/48ePZ+3atWzbtu2+y2RW9T0sybQELC0tCQkJYfPmzUb7N2/eTIcOHYo8pn379oXKb9q0idatW2NhYVFsmXudszLjBfUT/ejRo/n555957LHH7nsdRVGIjIzEy8vLJPHeLSIiwiiW6vb+gtor8dy5c4wZM+a+16mo97csTHn/lpWp7t+KUlX3b3mY6v5VFIVXX32VX375hT///JN69erd95gqv4dL3WXpIbV06VLFwsJCWbhwoXLixAll4sSJiq2traE32zvvvKOMGDHCUP7ChQuKjY2N8vrrrysnTpxQFi5cqFhYWCgrV640lNm9e7diZmamfPLJJ8rJkyeVTz75RDE3N1f27dtX5fH+/PPPirm5ufL1118rsbGxhi05OdlQZurUqcrGjRuV8+fPKxEREcpzzz2nmJubK/v376/yeGfNmqWsXr1aOXPmjHLs2DHlnXfeUQBl1apVhjLV6f0tMHz4cKVdu3ZFnrMy39+0tDQlIiJCiYiIUADliy++UCIiIpRLly4VGa+p79/Sxmvq+7e08Zr6/i1tvAVMdf++/PLLiqOjo7J9+3aj329mZqahjKnvYUmmpfD1118rfn5+iqWlpdKqVSujbtmjRo1SunTpYlR++/btSsuWLRVLS0ulbt26yvz58wudc8WKFUpAQIBiYWGhBAYGGv1nqsp4u3TpogCFtlGjRhnKTJw4UfH19VUsLS0VNzc3pVevXsqePXtMEu+MGTOUBg0aKFZWVoqzs7PSqVMnZd26dYXOWV3eX0VRlOTkZMXa2lpZsGBBkeerzPe3YCjGvX6/1e3+LW28pr5/Sxuvqe/fstwPprx/i4oVUBYvXmwoY+p7WJZgE0IIIcpJnpkKIYQQ5STJVAghhCgnSaZCCCFEOUkyFUIIIcpJkqkQQghRTpJMhRBCiHKSZCqEEEKUkyRTIUS5aTQa1qxZY+owhDAZSaZC1HCjR49Go9EU2vr06WPq0IR4aMgSbEI8APr06cPixYuN9ul0OhNFI8TDR2qmQjwAdDodnp6eRpuzszOgNsHOnz+fvn37Ym1tTb169VixYoXR8UePHuXRRx/F2toaFxcXXnrpJdLT043KLFq0iCZNmqDT6fDy8uLVV181+nlCQgKDBg3CxsYGf39/1q5da/jZjRs3GDZsGG5ublhbW+Pv718o+QtRk0kyFeIh8P777/Pkk09y5MgRhg8fzrPPPsvJkycByMzMpE+fPjg7O/PXX3+xYsUKtmzZYpQs58+fzyuvvMJLL73E0aNHWbt2LQ0bNjS6xrRp0xgyZAh///03/fr1Y9iwYSQlJRmuf+LECTZs2MDJkyeZP38+rq6uVfcGCFHZyjQ9vhCi2hg1apRiZmam2NraGm0ffvihoijqihtjx441OqZdu3bKyy+/rCiKoixYsEBxdnZW0tPTDT9ft26dotVqlbi4OEVRFMXb21t577337hkDoPzrX/8yfJ+enq5oNBplw4YNiqIoSv/+/ZXnnnuuYl6wENWQPDMV4gHQrVs35s+fb7SvVq1ahq/bt29v9LP27dsTGRkJwMmTJwkODsbW1tbw844dO6LX6zl9+jQajYarV6/SvXv3YmNo3ry54WtbW1vs7e2Jj48H4OWXX+bJJ5/k8OHD9OrVi4EDB5p0kWshKpokUyEeALa2toWaXe9Ho9EAoCiK4euiylhbW5fofBYWFoWO1ev1APTt25dLly6xbt06tmzZQvfu3XnllVf4/PPPSxWzENWVPDMV4iGwb9++Qt8HBgYCEBQURGRkJBkZGYaf7969G61WS6NGjbC3t6du3bps3bq1XDG4ubkxevRofvzxR2bPns2CBQvKdT4hqhOpmQrxAMjOziYuLs5on7m5uaGTz4oVK2jdujWdOnXip59+4sCBAyxcuBCAYcOG8cEHHzBq1CimTp3K9evXGT9+PCNGjMDDwwOAqVOnMnbsWNzd3enbty9paWns3r2b8ePHlyi+KVOmEBISQpMmTcjOzub333+ncePGFfgOCGFakkyFeABs3LgRLy8vo30BAQGcOnUKUHvaLl26lHHjxuHp6clPP/1EUFAQADY2Nvzxxx+89tprtGnTBhsbG5588km++OILw7lGjRpFVlYWs2bN4s0338TV1ZWnnnqqxPFZWloyefJkLl68iLW1NZ07d2bp0qUV8MqFqB40iqIopg5CCFF5NBoNq1evZuDAgaYORYgHljwzFUIIIcpJkqkQQghRTvLMVIgHnDzJEaLySc1UCCGEKCdJpkIIIUQ5STIVQgghykmSqRBCCFFOkkyFEEKIcpJkKoQQQpSTJFMhhBCinCSZCiGEEOUkyVQIIYQop/8HsfTQP64SMy4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2af0981-1dd0-4af9-87a9-ccaa2526ca08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> A thunderstorm is typically associated with a type of cloud called a cumulus.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is George Bernard Shaw.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    " \n",
    "for entry in test_data[:3]: \n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate( \n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    " \n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4508468-1160-4fa0-a2d0-28d0982eb662",
   "metadata": {},
   "source": [
    "Third answers is incorrect. Seems to be performing worse than the prompting with the whole instruction. Let's evaluate the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56861c1c-ff4d-4b85-8871-83e58a68ce49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 110/110 [01:38<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "#Generating the responses of the test set and add them to the test_set file\n",
    "from tqdm import tqdm\n",
    " \n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    " \n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    " \n",
    "with open(\"instruction-data-with-response-masked.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ded9aa36-646f-4906-9c80-ab2fbb5e1f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|| 110/110 [05:23<00:00,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 53.13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Generating the results\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255e7b6d-6222-450d-8512-6d3348b04aec",
   "metadata": {},
   "source": [
    "The instruction masking performes  better (53% vs 49% with the no masked instructions) This is not consistent with the observation is hte paper \"Instruction Tuning With Loss Over Instructions\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7cc746-4fd8-4cc2-a2eb-4fd174589611",
   "metadata": {},
   "source": [
    "***Variation 2:  Phi-3 prompting style.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa56a9-ad31-45d1-b639-4944a7b9d754",
   "metadata": {},
   "source": [
    "We will use the folowing  prompting template\n",
    "\n",
    "< user ><br>Identify the correct spelling of the following word: 'Occasion'<br>\n",
    "< assistant ><br>The correct spelling is 'Occasion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "536ea2f2-84d2-4a15-a04b-733c15eb4ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating the format input function\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"<|user|>\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b490862f-295b-4ea4-bd6c-0e3631a77c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating also the Instruction Dataset function\n",
    "import tiktoken\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "\n",
    "            ###################################################################\n",
    "            # NEW: Use `format_input_phi` and adjust the response text template\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n<|assistant|>:\\n{entry['output']}\"\n",
    "            ###################################################################\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab558bb4-c39c-4533-bab8-717f355581e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 1.636, Val loss 1.620\n",
      "Ep 1 (Step 000005): Train loss 1.060, Val loss 1.026\n",
      "Ep 1 (Step 000010): Train loss 0.881, Val loss 0.939\n",
      "Ep 1 (Step 000015): Train loss 0.878, Val loss 0.903\n",
      "Ep 1 (Step 000020): Train loss 0.817, Val loss 0.878\n",
      "Ep 1 (Step 000025): Train loss 0.737, Val loss 0.847\n",
      "Ep 1 (Step 000030): Train loss 0.779, Val loss 0.825\n",
      "Ep 1 (Step 000035): Train loss 0.645, Val loss 0.806\n",
      "Ep 1 (Step 000040): Train loss 0.757, Val loss 0.804\n",
      "Ep 1 (Step 000045): Train loss 0.564, Val loss 0.801\n",
      "Ep 1 (Step 000050): Train loss 0.662, Val loss 0.789\n",
      "Ep 1 (Step 000055): Train loss 0.896, Val loss 0.786\n",
      "Ep 1 (Step 000060): Train loss 0.670, Val loss 0.773\n",
      "Ep 1 (Step 000065): Train loss 0.564, Val loss 0.759\n",
      "Ep 1 (Step 000070): Train loss 0.523, Val loss 0.758\n",
      "Ep 1 (Step 000075): Train loss 0.533, Val loss 0.753\n",
      "Ep 1 (Step 000080): Train loss 0.559, Val loss 0.744\n",
      "Ep 1 (Step 000085): Train loss 0.480, Val loss 0.738\n",
      "Ep 1 (Step 000090): Train loss 0.532, Val loss 0.726\n",
      "Ep 1 (Step 000095): Train loss 0.391, Val loss 0.717\n",
      "Ep 1 (Step 000100): Train loss 0.486, Val loss 0.698\n",
      "Ep 1 (Step 000105): Train loss 0.525, Val loss 0.703\n",
      "Ep 1 (Step 000110): Train loss 0.537, Val loss 0.692\n",
      "Ep 1 (Step 000115): Train loss 0.467, Val loss 0.682\n",
      "<|user|> Convert the active sentence to passive: 'The chef cooks the meal every day.'  The meal is cooked every day by the chef.<|endoftext|>The U.S. government is planning to launch a new program to help the world's poorest countries develop their own nuclear weapons.  The program, called the Nuclear Weapons Initiative,\n",
      "Ep 2 (Step 000120): Train loss 0.377, Val loss 0.681\n",
      "Ep 2 (Step 000125): Train loss 0.362, Val loss 0.690\n",
      "Ep 2 (Step 000130): Train loss 0.337, Val loss 0.707\n",
      "Ep 2 (Step 000135): Train loss 0.268, Val loss 0.720\n",
      "Ep 2 (Step 000140): Train loss 0.286, Val loss 0.737\n",
      "Ep 2 (Step 000145): Train loss 0.257, Val loss 0.741\n",
      "Ep 2 (Step 000150): Train loss 0.203, Val loss 0.736\n",
      "Ep 2 (Step 000155): Train loss 0.286, Val loss 0.755\n",
      "Ep 2 (Step 000160): Train loss 0.387, Val loss 0.758\n",
      "Ep 2 (Step 000165): Train loss 0.273, Val loss 0.739\n",
      "Ep 2 (Step 000170): Train loss 0.177, Val loss 0.731\n",
      "Ep 2 (Step 000175): Train loss 0.244, Val loss 0.721\n",
      "Ep 2 (Step 000180): Train loss 0.314, Val loss 0.709\n",
      "Ep 2 (Step 000185): Train loss 0.327, Val loss 0.714\n",
      "Ep 2 (Step 000190): Train loss 0.195, Val loss 0.711\n",
      "Ep 2 (Step 000195): Train loss 0.200, Val loss 0.702\n",
      "Ep 2 (Step 000200): Train loss 0.152, Val loss 0.699\n",
      "Ep 2 (Step 000205): Train loss 0.231, Val loss 0.696\n",
      "Ep 2 (Step 000210): Train loss 0.257, Val loss 0.694\n",
      "Ep 2 (Step 000215): Train loss 0.279, Val loss 0.688\n",
      "Ep 2 (Step 000220): Train loss 0.167, Val loss 0.696\n",
      "Ep 2 (Step 000225): Train loss 0.153, Val loss 0.700\n",
      "Ep 2 (Step 000230): Train loss 0.132, Val loss 0.702\n",
      "<|user|> Convert the active sentence to passive: 'The chef cooks the meal every day.'  The meal is cooked every day by the chef.<|endoftext|>The new year is a time of great hope and optimism for the world. It is a time of hope for the world's poor and the poor's children. It is a time of\n",
      "Training completed in 17.12 minutes.\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "import time\n",
    "model=model.to(device)\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    " \n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    " \n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bb053c0e-74b3-4d8f-baae-6ded946efef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 110/110 [09:29<00:00,  5.18s/it]\n"
     ]
    }
   ],
   "source": [
    "#Updating the response generation\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "    tokenizer=tokenizer\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    # New: Adjust ###Response -> <|assistant|>\n",
    "    response_text = generated_text[len(input_text):].replace(\"<|assistant|>:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c58160d3-9ea8-4dd6-8804-d9ef6719ab70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  39%|                                       | 43/110 [02:21<04:25,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: The correct output is \"The German translation of 'Where is the bathroom?' is 'Wo ist die Toilette?'\". The model response is \"Wie alt bist du? Wie alt bist du?\".\n",
      "\n",
      "Score: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|| 110/110 [05:40<00:00,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 109 of 110\n",
      "Average score: 56.81\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Generating the results\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb05bcf-b803-42fa-a792-ddc5b6e5c499",
   "metadata": {},
   "source": [
    "Best score so far with 56.81%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712693dd-63ca-4939-8a37-29eee8a46a8e",
   "metadata": {},
   "source": [
    "***Variation 3: LORA***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "296bdf27-3836-4dc8-bd8e-ad230ef32d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class for implementing a LoRA layer that creates the matrices A and B, along with the alpha scaling factor \n",
    "#and the rank (r)\n",
    "import math\n",
    " \n",
    "class LoRALayer(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
    "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))\n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    " \n",
    "    def forward(self, x):  #x inputs\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Creating a layer to integrate LoRA weights into the original linear layers\n",
    "class LinearWithLoRA(torch.nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)\n",
    "\n",
    "#Replacing original linear layers with LoRA layers\n",
    "def replace_linear_with_lora(model, rank, alpha):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
    "        else:  #recursively apply the function\n",
    "            replace_linear_with_lora(module, rank, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7850370d-a37a-40e7-9984-28958da2b964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\355M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\355M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "#Loading the model \n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    " \n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    " \n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    " \n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    " \n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8f127b-dcd7-4d31-a9b8-d8bdce04ca81",
   "metadata": {},
   "source": [
    "Before substituting, we freeze the original model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b6cf1fae-c27c-415e-aee6-c16a093c01cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters before: 406,286,336\n",
      "Total trainable parameters after: 0\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters before: {total_params:,}\")\n",
    " \n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    " \n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3d4c73-5635-4a26-ada1-8d78d48c1017",
   "metadata": {},
   "source": [
    "Next, we replace the linear layers with the LoRA layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8f5896db-69cf-4a60-b2cf-acfca09aa5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable LoRA parameters: 7,898,384\n"
     ]
    }
   ],
   "source": [
    "#16 ia usual default choice. The higher the rank, the more trainable parameters. Alpha is \n",
    "#usually half, equal or double of rank\n",
    "replace_linear_with_lora(model, rank=16, alpha=16) \n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable LoRA parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a1e24a-5308-4bfd-9133-ebac9b316b2b",
   "metadata": {},
   "source": [
    "Number of parametes has been reduced by more than 50x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "db748a6e-728f-4245-9a62-fd132d256df2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 1024)\n",
      "  (pos_emb): Embedding(1024, 1024)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (12): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (13): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (14): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (15): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (16): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (17): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (18): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (19): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (20): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (21): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (22): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (23): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): LinearWithLoRA(\n",
      "    (linear): Linear(in_features=1024, out_features=50257, bias=False)\n",
      "    (lora): LoRALayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "39415cd5-4d03-48bd-977f-79f66f655fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.3913220882415773\n",
      "Validation loss: 2.2625602960586546\n"
     ]
    }
   ],
   "source": [
    "#Calculating the initial loss for the training and validation sets\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    " \n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    " \n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f771a680-2a73-4e7e-acb8-fa8da93d8596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 1.797, Val loss 1.760\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.099\n",
      "Ep 1 (Step 000010): Train loss 1.004, Val loss 1.014\n",
      "Ep 1 (Step 000015): Train loss 0.975, Val loss 0.986\n",
      "Ep 1 (Step 000020): Train loss 0.892, Val loss 0.940\n",
      "Ep 1 (Step 000025): Train loss 0.807, Val loss 0.909\n",
      "Ep 1 (Step 000030): Train loss 0.819, Val loss 0.886\n",
      "Ep 1 (Step 000035): Train loss 0.689, Val loss 0.854\n",
      "Ep 1 (Step 000040): Train loss 0.797, Val loss 0.852\n",
      "Ep 1 (Step 000045): Train loss 0.600, Val loss 0.840\n",
      "Ep 1 (Step 000050): Train loss 0.693, Val loss 0.823\n",
      "Ep 1 (Step 000055): Train loss 0.919, Val loss 0.834\n",
      "Ep 1 (Step 000060): Train loss 0.703, Val loss 0.829\n",
      "Ep 1 (Step 000065): Train loss 0.611, Val loss 0.822\n",
      "Ep 1 (Step 000070): Train loss 0.553, Val loss 0.824\n",
      "Ep 1 (Step 000075): Train loss 0.551, Val loss 0.821\n",
      "Ep 1 (Step 000080): Train loss 0.589, Val loss 0.812\n",
      "Ep 1 (Step 000085): Train loss 0.531, Val loss 0.801\n",
      "Ep 1 (Step 000090): Train loss 0.560, Val loss 0.780\n",
      "Ep 1 (Step 000095): Train loss 0.426, Val loss 0.771\n",
      "Ep 1 (Step 000100): Train loss 0.530, Val loss 0.755\n",
      "Ep 1 (Step 000105): Train loss 0.512, Val loss 0.745\n",
      "Ep 1 (Step 000110): Train loss 0.555, Val loss 0.737\n",
      "Ep 1 (Step 000115): Train loss 0.463, Val loss 0.743\n",
      "<|user|> Convert the active sentence to passive: 'The chef cooks the meal every day.'  The active sentence should be 'The meal is cooked every day.'<|endoftext|>The new iPhone 6S is a step forward for Apple. It's a step forward for the iPhone. It's a step forward for the iPhone. It's a step\n",
      "Ep 2 (Step 000120): Train loss 0.426, Val loss 0.767\n",
      "Ep 2 (Step 000125): Train loss 0.380, Val loss 0.770\n",
      "Ep 2 (Step 000130): Train loss 0.356, Val loss 0.795\n",
      "Ep 2 (Step 000135): Train loss 0.300, Val loss 0.807\n",
      "Ep 2 (Step 000140): Train loss 0.316, Val loss 0.800\n",
      "Ep 2 (Step 000145): Train loss 0.290, Val loss 0.792\n",
      "Ep 2 (Step 000150): Train loss 0.207, Val loss 0.782\n",
      "Ep 2 (Step 000155): Train loss 0.306, Val loss 0.785\n",
      "Ep 2 (Step 000160): Train loss 0.355, Val loss 0.790\n",
      "Ep 2 (Step 000165): Train loss 0.272, Val loss 0.776\n",
      "Ep 2 (Step 000170): Train loss 0.184, Val loss 0.767\n",
      "Ep 2 (Step 000175): Train loss 0.259, Val loss 0.758\n",
      "Ep 2 (Step 000180): Train loss 0.337, Val loss 0.743\n",
      "Ep 2 (Step 000185): Train loss 0.347, Val loss 0.745\n",
      "Ep 2 (Step 000190): Train loss 0.217, Val loss 0.759\n",
      "Ep 2 (Step 000195): Train loss 0.240, Val loss 0.762\n",
      "Ep 2 (Step 000200): Train loss 0.176, Val loss 0.755\n",
      "Ep 2 (Step 000205): Train loss 0.265, Val loss 0.744\n",
      "Ep 2 (Step 000210): Train loss 0.276, Val loss 0.738\n",
      "Ep 2 (Step 000215): Train loss 0.323, Val loss 0.741\n",
      "Ep 2 (Step 000220): Train loss 0.216, Val loss 0.758\n",
      "Ep 2 (Step 000225): Train loss 0.181, Val loss 0.757\n",
      "Ep 2 (Step 000230): Train loss 0.148, Val loss 0.753\n",
      "<|user|> Convert the active sentence to passive: 'The chef cooks the meal every day.'  The meal every day  The meal every day  The meal every day  The meal every day  The meal every day  The meal every day  The meal every day  The meal every day  \n",
      "Training completed in 15.29 minutes.\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "import time\n",
    " \n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    " \n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    " \n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0b0e5929-15fc-49c9-b2b3-ea919e90cff1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MaxNLocator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, num_epochs, \u001b[38;5;28mlen\u001b[39m(train_losses))\n\u001b[1;32m----> 2\u001b[0m plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\LLMs\\Finetuning_to_follow_instructions\\Classes.py:432\u001b[0m, in \u001b[0;36mplot_losses\u001b[1;34m(epochs_seen, tokens_seen, train_losses, val_losses)\u001b[0m\n\u001b[0;32m    430\u001b[0m ax1\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    431\u001b[0m ax1\u001b[38;5;241m.\u001b[39mlegend(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper right\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 432\u001b[0m ax1\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mset_major_locator(MaxNLocator(integer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))  \u001b[38;5;66;03m# only show integer labels on x-axis\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# Create a second x-axis for tokens seen\u001b[39;00m\n\u001b[0;32m    435\u001b[0m ax2 \u001b[38;5;241m=\u001b[39m ax1\u001b[38;5;241m.\u001b[39mtwiny()  \u001b[38;5;66;03m# Create a second x-axis that shares the same y-axis\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MaxNLocator' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e955264c-e309-4a95-8e88-347b753e2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After initiating Ollama3 we verify that is running\n",
    "import psutil\n",
    " \n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    " \n",
    "ollama_running = check_if_running(\"ollama\")\n",
    " \n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3f254ac3-bea5-42d3-8a8f-f739c1caebe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 110/110 [06:45<00:00,  3.68s/it]\n"
     ]
    }
   ],
   "source": [
    "#Generating the responses of the test set and add them to the test_set file\n",
    "from tqdm import tqdm\n",
    " \n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    " \n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    " \n",
    "with open(\"instruction-data-LoRA.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dfb7eeab-7e28-4887-8e62-edf00d09d489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  74%|                | 81/110 [04:24<03:33,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: The correct output is indeed: \"The number IX in Roman numerals is 9.\"\n",
      "\n",
      "Scoring the model response:\n",
      "\n",
      "1. Correctness (50/50): The model correctly converted the Roman numeral IX to its corresponding English number, which is 9.\n",
      "2. Clarity (25/25): The response is clear and easy to understand.\n",
      "3. Grammar and Spelling (0/10): There are no grammatical or spelling errors.\n",
      "\n",
      "Score: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|| 110/110 [05:54<00:00,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 109 of 110\n",
      "Average score: 53.78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Generating the results\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad08ef-acbf-4265-b2b6-166f73cfa07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba9b718-f310-4a2a-99a9-91149d5cbbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc78620-c37a-46d7-9884-f82c88ac9a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

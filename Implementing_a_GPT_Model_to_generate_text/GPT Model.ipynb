{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b29aa980-7d90-47e1-a360-6ba2959b5eec",
   "metadata": {},
   "source": [
    "Smallest version of GPT-2 model,  with 124 million parameters, as described in Radford's et al.'s paper, \"Language Models are Unsupervised Multitask Learners.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2a181f9-bffe-4612-80b1-a6ae9d724897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration of the model\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257, # Vocabulary size\n",
    "    \"ctx_len\": 1024, # Context length\n",
    "    \"emb_dim\": 768, # Embedding dimension\n",
    "    \"n_heads\": 12, # Number of attention heads\n",
    "    \"n_layers\": 12, # Number of layers\n",
    "    \"drop_rate\": 0.1, # Dropout rate\n",
    "    \"qkv_bias\": False # Query-Key-Value bias\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56470781-bad6-4b73-af9a-c3d5c0dc7c0f",
   "metadata": {},
   "source": [
    "Components of the models architecture:\n",
    "- Layer normalization\n",
    "- GELU activation\n",
    "- Feed forward network\n",
    "- Shortcut connections\n",
    "- Transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e44394-aef9-49ae-a47e-cbda30fc8b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we build the backbone of the model. The configuration is passed through a dictionary. The forward method describes the data flow through the model: \n",
    "#it computes token and #positional embeddings for the input indices, applies dropout, processes the data through #the transformer blocks, \n",
    "#applies normalization, and finally produces logits with the linear output layer\n",
    "import torch.nn as nn\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"ctx_len\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(*[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])# Placeholder for Transformer block\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"]) #Placeholder for LayerNorm \n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len,device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "        \n",
    "class DummyTransformerBlock(nn.Module): #Placeholder transformer class\n",
    "        def _\n",
    "    _init__(self, cfg):\n",
    "            super().__init__()\n",
    "        def forward(self, x): \n",
    "            return x\n",
    "            \n",
    "class DummyLayerNorm(nn.Module): #Placehoder fot Layer Normalization\n",
    "        def __init__(self, normalized_shape, eps=1e-5): \n",
    "            super().__init__()\n",
    "        def forward(self, x):\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc156d36-a3c3-4763-873c-70d3630ccda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "#Generating input\n",
    "import tiktoken\n",
    "import torch\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfab0bd0-fcaa-4f21-8d0a-c7cbbd0064dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
      "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
      "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
      "         [ 0.0448,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
      "\n",
      "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
      "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
      "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
      "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Initialiting and feeding the batch to the dummy model\n",
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1402957-adad-4ba8-abb9-f2857c987519",
   "metadata": {},
   "source": [
    "***Layer Normalization***\n",
    "\n",
    "The main idea behind layer normalization is to adjust the activations (outputs) of a neural network layer to have a mean of 0 and a variance of 1, also known as unit variance. This adjustment speeds up the convergence to effective weights and ensures consistent, reliable training. It is applied before and after the multi-head attention module and before the final output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "683ad89b-1b9d-48dc-822c-f5a00685e591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Example of a neural network with 5 inputs and 6 outputs\n",
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5) #2 training examples with 5 dimensions\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ea7553-b08e-4e15-b657-4c202092b2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Checking the mean and variance\n",
    "mean = out.mean(dim=-1, keepdim=True)#-1 refers to the last dimension of the tensoer. In this case equals to dim=1\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1541182-f605-48b7-ac8f-5c386472ea4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[9.9341e-09],\n",
      "        [5.9605e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Applying layer normalization:\n",
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73205f0e-aa01-4b29-9de0-f099cd261821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Turning off scientific notation\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9202e627-ec14-4580-96e1-026373f31247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating norrmalization module. Scale and shifting are trainable parameters automatically adjusted during training.\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5 #to prevent division by zero during normalization. \n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)#unbiased False does not apply Bessel's correction, following the original GPT-2 implementation\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4074a67-dfc2-4ecc-9f72-1de8d5e75706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Applying the layer normalization to an example\n",
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)\n"
   ]
  },
  {
   "attachments": {
    "c043f00e-560a-4f12-b7df-4fd8e34308de.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "f687a5ca-277c-408c-85ff-64b98e699836",
   "metadata": {},
   "source": [
    "***GELU activation***\n",
    "\n",
    "Implementing GELU approximation\n",
    "\n",
    "![image.png](attachment:c043f00e-560a-4f12-b7df-4fd8e34308de.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2208be8a-8950-4498-ba8f-1ab1c413a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *(x + 0.044715 * torch.pow(x, 3))\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d78bb360-1b3d-4bb0-8e20-874f1577344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a feed forward module which uses GELU function\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),GELU(),nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        nn.Dropout(cfg[\"drop_rate\"]))\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "194cb9bd-35bb-433e-8b71-d3c2d346561b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768) #A\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fbefb7-cd87-48aa-95e7-af158b83c065",
   "metadata": {},
   "source": [
    "***Shortcut connections***\n",
    "\n",
    "Shorcut connections are used to mitigate the challenge of vanishing gradients. Shortcut connections involve adding the inputs of a layer to its\n",
    "outputs, effectively creating an alternate path that bypasses certain layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4e25117-a2f1-4cbc-80d2-d14acb9235f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code of shortcut connection\n",
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "        # Implement 5 layers\n",
    "        nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]),GELU()),\n",
    "        nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]),GELU()),\n",
    "        nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]),GELU()),\n",
    "        nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]),GELU()),\n",
    "        nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]),GELU())\n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of the current layer\n",
    "            layer_output = layer(x)\n",
    "            # Check if shortcut can be applied\n",
    "            if self.use_shortcut and x.size() == layer_output.size():\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a25ebd8-b483-4759-a73d-463db3787ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example without shortcuts\n",
    "layer_sizes = [3, 3, 3, 3, 3, 1] #each layer will be initialized such that it accepts an example with 3 input values and returns 3 output values. The last layer returns a single output value:\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123) # specify random seed for the initial weights forreproducibility\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ee9e1ec-9a16-4794-9f3f-7648b5684ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compute the grdient's in the backward pass\n",
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "    # Calculate loss based on how close the target\n",
    "    # and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    for name, param in model.named_parameters(): #n iterate through the weight parameters \n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fce84652-61ef-4bea-9339-feb793884514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173590746708214\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152042235247791\n",
      "layers.3.0.weight has gradient mean of 0.0013988739810883999\n",
      "layers.4.0.weight has gradient mean of 0.00504964729771018\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b424c11-8c27-4510-95d4-a91d23b03bc5",
   "metadata": {},
   "source": [
    "The gradients become smaller as we progress from the last layer (layers.4) to the first layer (layers.0),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2600078d-1db7-48d8-a9d8-11cc37ebfa89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169791162014008\n",
      "layers.1.0.weight has gradient mean of 0.20694102346897125\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
     ]
    }
   ],
   "source": [
    "#Model with skip connections\n",
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=True)\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6533fadd-4219-4ae4-8b6b-4fd0f9023e68",
   "metadata": {},
   "source": [
    "The gradient value stabilizes as we progress towards the first layer (layers.0) and doesn't shrink to a vanishingly small value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923847e7-ffbd-4609-a02b-d7a4d2e498c0",
   "metadata": {},
   "source": [
    "***Transformer block***\n",
    "\n",
    "Transformer block connects the components above: multi-head attention, layer normalization, dropout, feed forward layers, and GELU activations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cbf5931c-1b31-4324-a826-b1cbec958821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Classes import MultiHeadAttention\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"ctx_len\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_resid = nn.Dropout(cfg[\"drop_rate\"])\n",
    "    \n",
    "    def forward(self, x):\n",
    "   \n",
    "        shortcut = x       #Shortcut connection for attention block\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_resid(x)\n",
    "        x = x + shortcut #Add the original input back\n",
    "        \n",
    "        shortcut = x #Shortcut connection for feed forward block\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_resid(x)\n",
    "        x = x + shortcut #Add the original input back\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5bb7099-6132-4e91-954c-6f478129a37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "#Instantiating a transformer block\n",
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768) #A\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3daa08-f043-454e-a0f9-c7f6c44771c5",
   "metadata": {},
   "source": [
    "***Coding the GPT model***\n",
    "\n",
    "Tokenized text is first converted into token embeddings, which are then augmented with positional embeddings. This combined information forms a tensor that is passed through a series of transformer blocks shown in the center (each containing multi-head attention and feed forward neural network layers with dropout and layer normalization), which are stacked on top of each other and repeated 12 times. The output from the final transformer block goes through a final layer normalization step before reaching the linear output layer. This layer maps the transformer's output to a high-dimensional space (in this case, 50,257 dimensions, corresponding to the model's vocabulary size) to predict the next token in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "54a93622-f410-489f-85f6-2ea08d464727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"ctx_len\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"]) \n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len,device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "    \n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f507162-12af-4ee4-a3c2-cbbd9e94bdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.3836,  0.1907, -0.2999,  ...,  0.0701, -0.3504, -0.8911],\n",
      "         [ 0.3457, -0.4659, -0.7705,  ..., -0.3331,  0.0161,  0.1663],\n",
      "         [ 0.9492, -0.1808, -0.0225,  ...,  0.2096, -0.3042, -0.1051],\n",
      "         [-0.8163,  0.3850, -0.2297,  ...,  1.0137,  0.4000, -0.4916]],\n",
      "\n",
      "        [[ 0.0851,  0.1240, -0.0751,  ...,  0.5713,  0.2818, -0.6030],\n",
      "         [ 0.0400, -0.2573,  0.0609,  ...,  0.5641, -0.1687,  0.3409],\n",
      "         [ 0.9161,  1.0140, -0.2341,  ...,  0.2165,  0.5243,  0.1291],\n",
      "         [ 0.1589,  0.2120,  0.6350,  ...,  0.9529, -0.1897, -0.3581]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e34183-7bef-45aa-86cf-13414a43255a",
   "metadata": {},
   "source": [
    "The last dimension, 50,257, corresponds to the vocabulary size of the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f726b2-d181-41a6-ac5e-29109f7f4210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numel() method, short for \"number of elements,\" to collect the total number of parameters in the model's parameter tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8b18bb54-a6c9-47db-b249-4089310e93be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa4a8ff-7ddf-49ac-a9b7-f9b901489b14",
   "metadata": {},
   "source": [
    "***Generating text***\n",
    "\n",
    "Code that converts the tensor outputs of the GPT model back into text. Thisincludes decoding the output tensors, selecting tokens based on a probability distribution, and converting these tokens into human-readable text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3b3c12b-b1c6-444e-a5f7-6a0651d6ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple implementation of a generative loop for a language model\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size): #idx is (B, T) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:] #Crop current context if it exceeds the supported context size\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :] #Focus only on the last time step, so that (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
    "        probas = torch.softmax(logits, dim=-1) #probas has shape (batch, vocab_size)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True) #idx_next has shape (batch, 1)\n",
    "        idx = torch.cat((idx, idx_next), dim=1) # (batch, n_tokens+1) #Append sampled index to the running sequence\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "398dcd17-9ce2-4df9-9093-34d121f6dd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #Adding a batch dimension\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5864cc9d-4652-4a0c-b19e-2a93606b7493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "#mode evaldisables random components like dropout, which are only used during training\n",
    "model.eval() \n",
    "out = generate_text_simple(model=model, idx=encoded_tensor,max_new_tokens=6,context_size=GPT_CONFIG_124M[\"ctx_len\"])\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6887bcbe-ecbb-4b91-a687-69af3584782f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d2ee49-45a3-42cc-befa-c70f0a2fb87e",
   "metadata": {},
   "source": [
    "The model is untrained which expalins hence the random output text above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a25e55b-fc03-4b6b-9735-8c5dd5028028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
